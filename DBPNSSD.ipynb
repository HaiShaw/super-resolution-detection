{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The following code is modified based on the original torchcv project. \n",
    "* We are going to use PASACAL VOC12 as dataset.\n",
    "* You could donwload VOC2012 \n",
    "  train/validation: http://host.robots.ox.ac.uk/pascal/VOC/voc2012/#devkit\n",
    "* test data: https://pjreddie.com/projects/pascal-voc-dataset-mirror/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from __future__ import print_function\n",
    "from dbpn import Net as DBPN\n",
    "from dbpn import get_pair_set\n",
    "from ssd import SSD\n",
    "from ssd import build_ssd\n",
    "from ssd.layers.modules import MultiBoxLoss\n",
    "from ssd.data.config import voc\n",
    "from ssd.data import detection_collate\n",
    "from ssd.data import VOCAnnotationTransform, VOCDetection, BaseTransform, SRDetection, DBPNLoader\n",
    "from ssd.eval import test_net\n",
    "\n",
    "import sys; sys.argv=['']; del sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Setup - We use VOC07 for validation\n",
    "\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "voc_root = os.path.join(HOME, \"data/VOCdevkit/\")\n",
    "\n",
    "annopath = os.path.join(voc_root, 'VOC2007', 'Annotations', '%s.xml')\n",
    "imgpath = os.path.join(voc_root, 'VOC2007', 'JPEGImages', '%s.jpg')\n",
    "imgsetpath = os.path.join(voc_root, 'VOC2007', 'ImageSets', 'Main', '{:s}.txt')\n",
    "YEAR = '2007'\n",
    "devkit_path = voc_root + 'VOC' + YEAR\n",
    "dataset_mean = (104, 117, 123)\n",
    "\n",
    "set_type = '07val32-5702'\n",
    "# set_typs is explained below:\n",
    "\"\"\"\n",
    "We have 5 validation sets to choose, size of 16, 32, 64, 128, 256 repectively,\n",
    "Due to the time & computation constraint, we have these 5 downsampled val set.\n",
    "They are randomly(no replacement) picked from  VOC2007/ImageSets/Main/val.txt.\n",
    "\n",
    "Baseline mAP on Pre-trained ssd300 is measured as well:       (mAP)\n",
    "These Detection baseline are measured on frozen SSD300 network using\n",
    "'weights/ssd300_mAP_77.43_v2.pth', for 75x75 LR images been SR-ed by\n",
    "VOC12 retrained DBPN baseline w. weight 'VOC12-LR-x4-DBPN-ep100.pth'.\n",
    "\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val16-5648.txt      56.48%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val32-5702.txt      57.02%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val64-5826.txt      58.26%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val128-6019.txt     60.19%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val256-6030.txt     60.30%\n",
    "\n",
    "These can be used to evaluate training in progress quantatively.\n",
    "Again we do not run through whole val set for periodical check out, too slow!\n",
    "\"\"\"\n",
    "\n",
    "def save_img(img, img_path):\n",
    "    save_img = img.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n",
    "    cv2.imwrite(img_path, cv2.cvtColor(save_img*255, cv2.COLOR_BGR2RGB),  [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "eval_set = DBPNLoader(root='./dataset')\n",
    "eval_loader = DataLoader(dataset=eval_set, batch_size=1, num_workers=1, shuffle=False)\n",
    "#torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(anno_path='Annotations', batch_size=4, checkpt='./checkpoint', gpu_mode=True, gpus=1, hr_dataset='VOC12-HR', imSetpath='ImageSets', input_dir='./dataset', lr=0.0001, nEpochs=5, seed=123, testBatchSize=1, threads=4, train_dataset='VOC12-LR-x4', upscale_factor=4)\n"
     ]
    }
   ],
   "source": [
    "# Arguments & settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch Super Resolution Detection Networks')\n",
    "parser.add_argument('--upscale_factor', type=int, default=4, help=\"super resolution upscale factor\")\n",
    "parser.add_argument('--testBatchSize', type=int, default=1, help='testing batch size')\n",
    "parser.add_argument('--batch_size', type=int, default=4, help='training batch size') # GPU: 9GB!\n",
    "parser.add_argument('--threads', type=int, default=4, help='number of threads for data loading')\n",
    "parser.add_argument('--seed', type=int, default=123, help='random seed to use. Default=123')\n",
    "parser.add_argument('--gpu_mode', type=bool, default=True)\n",
    "parser.add_argument('--gpus', default=1, type=float, help='number of gpu')\n",
    "#parser.add_argument('--test_dataset', type=str, default='VOC12-LR-X8-test')\n",
    "#parser.add_argument('--sr_dataset', type=str, default='VOC12-SR-X8')\n",
    "parser.add_argument('--train_dataset', type=str, default='VOC12-LR-x4')\n",
    "parser.add_argument('--hr_dataset', type=str, default='VOC12-HR')\n",
    "parser.add_argument('--anno_path', type=str, default='Annotations')\n",
    "parser.add_argument('--imSetpath', type=str, default='ImageSets')\n",
    "parser.add_argument('--input_dir', type=str, default='./dataset')\n",
    "#parser.add_argument('--output', default='./dataset/results', help='Location to save some outputs')\n",
    "parser.add_argument('--checkpt', default='./checkpoint', help='Location to save checkpoint models')\n",
    "parser.add_argument('--lr', type=float, default=1e-4, help='Learning Rate. Default=0.0001')\n",
    "parser.add_argument('--nEpochs', type=int, default=5, help='number of epochs to fine tune net S over target loss')\n",
    "\n",
    "opt = parser.parse_args()\n",
    "\n",
    "gpus_list=range(opt.gpus)\n",
    "print(opt)\n",
    "\n",
    "cuda = opt.gpu_mode\n",
    "if cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run without --cuda\")\n",
    "\n",
    "torch.manual_seed(opt.seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(opt.seed)\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading net S fine-tune training datasets\n"
     ]
    }
   ],
   "source": [
    "print('===> Loading net S fine-tune training datasets')\n",
    "# VOC0712 dataset mean\n",
    "MEANS = (104, 117, 123)\n",
    "\n",
    "sd_dataset = SRDetection(root='./dataset', image_sets='trainval.txt', data_mean = MEANS,\n",
    "                         target_transform = VOCAnnotationTransform())\n",
    "\n",
    "sd_data_loader = DataLoader(dataset=sd_dataset, batch_size=opt.batch_size, num_workers=opt.threads,\n",
    "                            shuffle=False, collate_fn=detection_collate, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 21                                  # +1 for background\n",
    "ssd300net = build_ssd('test', 300, num_classes)   # initialize SSD\n",
    "ssd300net.load_state_dict(torch.load('ssd/weights/ssd300_mAP_77.43_v2.pth'))\n",
    "ssd300net.eval()\n",
    "\n",
    "print('Finished loading SSD300 evaluation model!')\n",
    "# load DBPN SRed data, and run evaluation test.\n",
    "eval_det = VOCDetection(voc_root, [('2007', set_type)],\n",
    "                       BaseTransform(300, dataset_mean),\n",
    "                       VOCAnnotationTransform(), sr_path='./dataset/VOC07-SR-x4')\n",
    "if cuda:\n",
    "     ssd300net = ssd300net.cuda()\n",
    "     cudnn.benchmark = True\n",
    "# evaluation\n",
    "\n",
    "test_net('./eval', ssd300net, cuda, eval_det,\n",
    "         BaseTransform(ssd300net.size, dataset_mean), 5, 300, thresh=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# 1. come up with test/eval functions\n",
    "# 2. come up with visualization image\n",
    "\n",
    "class DBPN2SSD(nn.Module):\n",
    "    \n",
    "    def __init__(self, s_model_name, d_model_name, d_frozen):\n",
    "        super(DBPN2SSD, self).__init__()\n",
    "        self.supervis = DBPN(num_channels=3, base_filter=64, feat=256, num_stages=7, scale_factor=4)\n",
    "        if os.path.exists(s_model_name):\n",
    "            self.supervis = torch.nn.DataParallel(self.supervis, device_ids=gpus_list)\n",
    "            self.supervis.load_state_dict(torch.load(s_model_name, map_location=lambda storage, loc: storage))\n",
    "\n",
    "        # self.detector = SSD(), setup ssd as 'train' mode for gradient flow\n",
    "        # later at test/eval situation, we will overwrite it's mode to 'test'\n",
    "        self.detector = build_ssd('train', 300, 21)\n",
    "        if os.path.exists(d_model_name):\n",
    "            self.detector.load_state_dict(torch.load(d_model_name, map_location=lambda storage, loc: storage))\n",
    "        if d_frozen:\n",
    "            for param in self.detector.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        superx = self.supervis(x)\n",
    "        # current detector: SSD300, so assume superx: 300x300!\n",
    "        detect = self.detector(superx)\n",
    "        return (superx, detect)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SRDnet = DBPN2SSD('dbpn/models/VOC12-LR-x4-DBPN-ep100.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "\n",
    "#dbpnet = SRDnet.supervis\n",
    "dbpnet = SRDnet\n",
    "\n",
    "if cuda:\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    # dbpnet = torch.nn.DataParallel(dbpnet)\n",
    "    cudnn.benchmark = True\n",
    "    dbpnet = dbpnet.cuda(gpus_list[0])\n",
    "\n",
    "#dbpn_eval(dbpnet, eval_set, cuda)\n",
    "\n",
    "eval_set = DBPNLoader(root='./dataset')\n",
    "eval_loader = DataLoader(dataset=eval_set, batch_size=1, num_workers=1, shuffle=False)\n",
    "\n",
    "#def dbpn_eval(dbpnet, eval_loader, cuda):\n",
    "dbpnet.eval()\n",
    "#num_images = len(eval_set)\n",
    "#for i in range(num_images):\n",
    "for iteration, batch in enumerate(eval_loader, 1):\n",
    "    # input is LR image; sr_target is pseudo (300x300) original HR image, det_target is bboxes\n",
    "    # input, sr_target = batch[0], batch[1]\n",
    "    lr, hr, fname = batch[0], batch[1], batch[2]\n",
    "    # lr, hr, fname = eval_set.pull_item(i)\n",
    "    if cuda:\n",
    "        lr_v = Variable(lr.cuda(gpus_list[0]))\n",
    "    else:\n",
    "        lr_v = Variable(lr)\n",
    "    sr, _ = dbpnet(lr_v)\n",
    "    srimg = sr.cpu().data\n",
    "    image=srimg\n",
    "    image = (image - image.min())/(image.max() - image.min())\n",
    "    srimg=image\n",
    "    #save_img = srimg.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n",
    "    imagef = os.path.join('./dataset/VOC07-SR-x4/', '%s.jpg')\n",
    "    save_img(srimg, imagef % fname)\n",
    "    #save_fn = imagef % fname\n",
    "    #print(save_fn)\n",
    "    #print(save_img.shape)\n",
    "    #cv2.imwrite(save_fn, cv2.cvtColor(save_img * 255, cv2.COLOR_BGR2RGB),  [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "#dbpnet.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x/cs231n/super-resolution-detection/ssd/ssd.py:34: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.priors = Variable(self.priorbox.forward(), volatile=True)\n",
      "/home/x/cs231n/super-resolution-detection/ssd/layers/modules/l2norm.py:17: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.weight,self.gamma)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading SSD300 evaluation model!\n",
      "Evaluating detections\n",
      "VOC07 metric? Yes\n",
      "Mean AP = 0.5669\n",
      "~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "num_classes = 21                                  # +1 for background\n",
    "ssd300net = build_ssd('test', 300, num_classes)   # initialize SSD\n",
    "ssd300net.load_state_dict(torch.load('ssd/weights/ssd300_mAP_77.43_v2.pth'))\n",
    "ssd300net.eval()\n",
    "\n",
    "print('Finished loading SSD300 evaluation model!')\n",
    "# load DBPN SRed data, and run evaluation test.\n",
    "eval_det = VOCDetection(voc_root, [('2007', set_type)],\n",
    "                       BaseTransform(300, dataset_mean),\n",
    "                       VOCAnnotationTransform(), sr_path='./dataset/VOC07-SR-x4')\n",
    "if cuda:\n",
    "     ssd300net = ssd300net.cuda()\n",
    "     cudnn.benchmark = True\n",
    "# evaluation\n",
    "\n",
    "test_net('./eval', ssd300net, cuda, eval_det,\n",
    "         BaseTransform(ssd300net.size, dataset_mean), 5, 300, thresh=0.01, eval_set=set_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SRDnet = DBPN2SSD('dbpn/models/VOC12-LR-x4-DBPN-ep100.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "\n",
    "#dbpnet = SRDnet.supervis\n",
    "dbpnet = SRDnet\n",
    "\n",
    "if cuda:\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    dbpnet = torch.nn.DataParallel(dbpnet)\n",
    "    cudnn.benchmark = True\n",
    "    dbpnet = dbpnet.cuda(gpus_list[0])\n",
    "\n",
    "dbpn_eval(dbpnet, eval_set, cuda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters - balancing weights of net S loss vs. net D loss\n",
    "alpha = 1.0\n",
    "beta = 1.0\n",
    "\n",
    "decay_steps = [5000, 10000, 20000, 40000, 80000, 160000]\n",
    "gamma = 0.1\n",
    "def adjust_learning_rate(optimizer, gamma=0.1, step=0):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every\n",
    "        specified step\n",
    "    # Adapted from PyTorch Imagenet example:\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    lr = opt.lr * (gamma ** (step))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def train():\n",
    "    #SDnet = DBPN2SSD('dbpn/models/DBPN_x4.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "    #SDnet = DBPN2SSD('checkpoint/SRx4_4000.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "    SDnet = DBPN2SSD('dbpn/models/VOC12-LR-x4-DBPN-ep100.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "    \n",
    "    net = SDnet\n",
    "\n",
    "    # Criterions:\n",
    "    #\n",
    "    # net SR loss function, change to L2 later\n",
    "    criterion_sr = nn.MSELoss()\n",
    "\n",
    "    # ssd loss function\n",
    "    criterion_ssd = MultiBoxLoss(voc['num_classes'], 0.5, True, 0, True, 3, 0.5, False, use_gpu=cuda)\n",
    "\n",
    "    if cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        #net.supervis = torch.nn.DataParallel(net.supervis)\n",
    "        cudnn.benchmark = True\n",
    "        net = net.cuda(gpus_list[0])\n",
    "        criterion_sr = criterion_sr.cuda(gpus_list[0])\n",
    "        criterion_ssd = criterion_ssd.cuda(gpus_list[0])\n",
    "\n",
    "\n",
    "    # optimizer = optim.SGD(net.supervis.parameters(), lr=opt.lr, \\\n",
    "    #                       momentum=opt.momentum, weight_decay=opt.weight_decay)\n",
    "    #\n",
    "    # Use universal Adam first :)\n",
    "    # we can be Specific to what part of network's parameters to optimize, here is SuperR Net\n",
    "    optimizer = optim.Adam(net.supervis.parameters(), lr=opt.lr, betas=(0.9, 0.999), eps=1e-8)\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # set model to training mode\n",
    "    net.train()\n",
    "    \n",
    "    epoch = 1\n",
    "    max_iter = 20000\n",
    "    decay_step = 0\n",
    "    for iteration, batch in enumerate(sd_data_loader, 1):\n",
    "        \n",
    "        if iteration == max_iter:\n",
    "            break\n",
    "        if iteration in decay_steps:\n",
    "            decay_step += 1\n",
    "            adjust_learning_rate(optimizer, gamma, decay_step)\n",
    "            \n",
    "        # input is LR image; sr_target is pseudo (300x300) original HR image, det_target is bboxes\n",
    "        input, sr_target, det_target = batch[0], batch[1], batch[2]\n",
    "        if cuda:\n",
    "            input = Variable(input.cuda(gpus_list[0]))\n",
    "            sr_target = Variable(sr_target.cuda(gpus_list[0]))\n",
    "            det_target = [Variable(ann.cuda(gpus_list[0]), volatile=True) for ann in det_target]\n",
    "        else:\n",
    "            input = Variable(input)\n",
    "            sr_target = Variable(sr_target)\n",
    "            det_target = [Variable(ann, volatile=True) for ann in det_target]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        t0 = time()\n",
    "        \n",
    "        sr_out,ssd_out = net(input)\n",
    "        loss_sr = criterion_sr(sr_out, sr_target)\n",
    "        \n",
    "        # Compound Loss from net-S: loss_sr and net-D: loss_l, loss_c\n",
    "        loss_l, loss_c = criterion_ssd(ssd_out, det_target)\n",
    "        loss = loss_sr * alpha + beta *(loss_l + loss_c)\n",
    "        \n",
    "        epoch_loss += loss.data[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t1 = time()\n",
    "\n",
    "        if iteration != 0 and iteration % 2000 == 0:\n",
    "            print('Saving state, iter:', iteration)\n",
    "            torch.save(net.supervis.state_dict(), opt.checkpt + '/' + 'SRx4_' + repr(iteration+4000) + '.pth')\n",
    "        \n",
    "        print(\"===> Epoch[{}]({}/{}): Loss: {:.4f} || Timer: {:.4f} sec.\".format(epoch, \\\n",
    "                    iteration, len(sd_data_loader), loss.data[0], (t1 - t0)))\n",
    "\n",
    "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(sd_data_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(img, img_name):\n",
    "    save_img = img.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n",
    "\n",
    "    # save img\n",
    "    save_dir=os.path.join(opt.output,opt.test_dataset)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    save_fn = save_dir +'/'+ img_name\n",
    "    cv2.imwrite(save_fn, cv2.cvtColor(save_img*255, cv2.COLOR_BGR2RGB),  [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "    \n",
    "def eval():\n",
    "\n",
    "    net = DBPN2SSD('dbpn/models/VOC12-LR-x4-DBPN-ep100.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "    #net = DBPN2SSD('dbpn/models/DBPN_x4.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "\n",
    "    if cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        #net.supervis = torch.nn.DataParallel(net.supervis)\n",
    "        cudnn.benchmark = True\n",
    "        net = net.cuda(gpus_list[0])\n",
    "\n",
    "    net.eval()\n",
    "    \n",
    "    pred_boxes = []\n",
    "    pred_labels = []\n",
    "    pred_scores = []\n",
    "    gt_boxes = []\n",
    "    gt_labels = []\n",
    "\n",
    "    ###img_mean = np.array(MEANS, dtype=np.float32)\n",
    "\n",
    "    #box_coder = SSDBoxCoder()\n",
    "    #for iteration, batch in enumerate(eval_data_loader, 1):\n",
    "    for iteration, batch in enumerate(sd_data_loader, 1):\n",
    "        \n",
    "        # input is LR image; sr_target is pseudo (300x300) original HR image, det_target is bboxes\n",
    "        # input, sr_target = batch[0], batch[1]\n",
    "        input, sr_target, det_target = batch[0], batch[1], batch[2]\n",
    "\n",
    "        if cuda:\n",
    "            input_v = Variable(input.cuda(gpus_list[0]), volatile=True)\n",
    "            #sr_target = Variable(sr_target.cuda(gpus_list[0]))\n",
    "            ###ssd_target = [Variable(ann.cuda(gpus_list[0]), volatile=True) for ann in det_target]\n",
    "        else:\n",
    "            input_v = Variable(input, volatile=True)\n",
    "            #sr_target = Variable(sr_target)\n",
    "            ###ssd_target = [Variable(ann, volatile=True) for ann in det_target]\n",
    "\n",
    "        sr_img, ssd_out = net(input_v)\n",
    "        ###sr_img = net(input_v)\n",
    "        ###sr_img = sr_img.cpu().detach().numpy()\n",
    "        srimg = sr_img.cpu().data\n",
    "        image=srimg\n",
    "        image = (image - image.min())/(image.max() - image.min())\n",
    "        srimg=image\n",
    "        save_img(srimg, 'SuperRtest.jpg')\n",
    "        \n",
    "        #img_input = input_v.squeeze().cpu().numpy().transpose(1,2,0) + img_mean\n",
    "        img_input = input_v.squeeze().cpu().numpy().transpose(1,2,0)\n",
    "        img_input = img_input*255\n",
    "        img_input = np.clip(img_input, 0, 255)\n",
    "        #plt.imshow(sr_target.squeeze().clamp(0, 1).numpy().transpose(1,2,0))\n",
    "        #plt.imshow(sr_target[0].transpose((1,2,0)))\n",
    "        print(np.max(img_input))\n",
    "        print(np.min(img_input))\n",
    "\n",
    "        ### all good so far!!!\n",
    "        plt.imshow(img_input.astype(np.uint8))\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        #img0 = Image.fromarray(sr_img[0].transpose((1,2,0)), 'RGB')\n",
    "        #plt.imshow(sr_img[0].transpose((1,2,0)))\n",
    "        #plt.show()\n",
    "\n",
    "        rimg = srimg.numpy()\n",
    "        # debug SR imge display issue, clue: sr_img range from DBPN output [-11070.912, 12110.84] !!!\n",
    "        print(rimg.shape)\n",
    "        print(rimg[0].shape)\n",
    "        mx = np.max(rimg)\n",
    "        mi = np.min(rimg)\n",
    "        gp = mx - mi\n",
    "        print(mx)\n",
    "        print(mi)\n",
    "        #img_sr = sr_img.squeeze().transpose(1,2,0) + img_mean\n",
    "        #img_sr = (rimg.squeeze().transpose(1,2,0) /- mi) / gp + img_mean / 255.\n",
    "        #img_sr = ((rimg.squeeze().transpose(1,2,0) / mx) + 1.0) / 2.0 + img_mean / 255.\n",
    "        img_sr = rimg.squeeze().transpose(1,2,0)\n",
    "        #img_sr = img_sr*255 + img_mean\n",
    "        img_sr = img_sr*255\n",
    "        img_sr = np.clip(img_sr, 0, 255)\n",
    "        ###img_sr = img_sr * 255.\n",
    "        ###img_sr = np.clip(img_sr, 0, 255)\n",
    "        ###plt.imshow(img_sr.astype(np.uint8))\n",
    "        ###img_sr = srimg.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n",
    "        \n",
    "        # !! after use eval_data_loader (instead of sd_data_loader) this SRed image show great !!\n",
    "        plt.imshow(img_sr.astype(np.uint8))\n",
    "        plt.show()\n",
    "        ###print(np.max(img_sr))\n",
    "        ###print(np.min(img_sr))\n",
    "\n",
    "\n",
    "        \n",
    "        print(sr_target.shape)\n",
    "        print(sr_target[0].shape)\n",
    "        #img1 = Image.fromarray(sr_img[0].transpose((1,2,0)), 'RGB')\n",
    "        #img1 = sr_target.squeeze().numpy().transpose(1,2,0) + img_mean\n",
    "        #img_target = sr_target.squeeze().numpy().transpose(1,2,0) + img_mean\n",
    "        img_target = sr_target.squeeze().numpy().transpose(1,2,0)\n",
    "        img_target = img_target\n",
    "        img_target = np.clip(img_target, 0, 255)\n",
    "        #plt.imshow(sr_target.squeeze().clamp(0, 1).numpy().transpose(1,2,0))\n",
    "        #plt.imshow(sr_target[0].transpose((1,2,0)))\n",
    "        print(np.max(img_target))\n",
    "        print(np.min(img_target))\n",
    "\n",
    "        ### all good so far!!!\n",
    "        plt.imshow(img_target.astype(np.uint8))\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        target = sr_target.numpy()\n",
    "        \n",
    "        # create PSNR/SSIM\n",
    "        s_img = sr_img\n",
    "        #ssim = metric_ssim(target,sr_img)\n",
    "        #psnr = metric_psnr(target,sr_img)\n",
    "        \n",
    "        # Get the target box and lables\n",
    "        #print(\"ssim, psnr\",ssim,psnr)\n",
    "        ###box_targets = ssd_target[0][:,:-1]\n",
    "        ###label_targets = ssd_target[0][:,-1]\n",
    "        ###gt_boxes.append(box_targets.squeeze(0))\n",
    "        ###gt_labels.append(label_targets.squeeze(0))\n",
    "\n",
    "        ###loc_preds = ssd_out[0][:,:-1]\n",
    "        ###cls_preds = ssd_out[0][:,-1]\n",
    "        #box_preds, label_preds, score_preds = box_coder.decode(\n",
    "        #    loc_preds.cpu().data.squeeze(),\n",
    "        #    F.softmax(cls_preds.squeeze(), dim=1).cpu().data,\n",
    "        #    score_thresh=0.01)\n",
    "\n",
    "        #pred_boxes.append(box_preds)\n",
    "        #pred_labels.append(label_preds)\n",
    "        #pred_scores.append(score_preds)\n",
    "        ## img = Image.fromarray(sr_img[0].transpose((1,2,0)), 'RGB')\n",
    "        ## target = Image.fromarray(target[0].transpose((1,2,0)), 'RGB')\n",
    "        ## img = sr_img.squeeze().numpy().transpose(1,2,0) + img_mean\n",
    "        \n",
    "        ### sr_img changed by metric_ssim or metric_psnr functions ???\n",
    "        #####img = s_img.squeeze().transpose(1,2,0) + img_mean\n",
    "        #####img = np.clip(img, 0, 255)\n",
    "        #draw = ImageDraw.Draw(img)\n",
    "        #for box in loc_preds:BaseTransform\n",
    "            #print(\"listbox\",list(box))\n",
    "            #draw.rectangle(list(box), outline='red')\n",
    "        #print(\"sr_img shape\",sr_target.shape)        \n",
    "        #####plt.imshow(img.astype(np.uint8))\n",
    "        #####plt.show()\n",
    "\n",
    "        #target = sr_target.squeeze().numpy().transpo-se(1,2,0) + img_mean\n",
    "        \n",
    "        ## why here shows the reversed (negative) image, 20 lines above plt.show is good!\n",
    "        #im_target = sr_target.squeeze().numpy().transpose(1,2,0) + img_mean\n",
    "        im_target = sr_target.squeeze().numpy().transpose(1,2,0)\n",
    "        im_target = im_target\n",
    "        im_target = np.clip(im_target, 0, 255)\n",
    "        \n",
    "\n",
    "        plt.imshow(im_target.astype(np.uint8))\n",
    "        plt.show()\n",
    "        \n",
    "        save_img(torch.from_numpy(sr_target),\"test.jpeg\")\n",
    "\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging code below, no need to run :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' YOU Donot need to run this ===> Loading some datasets')\n",
    "\n",
    "lr_path = os.path.join(opt.input_dir, opt.train_dataset)\n",
    "hr_path = os.path.join(opt.input_dir, opt.hr_dataset)\n",
    "\n",
    "fine_train_set = get_pair_set(lr_path, hr_path)\n",
    "train_data_loader = DataLoader(dataset=fine_train_set, num_workers=opt.threads, \\\n",
    "                               batch_size=opt.testBatchSize, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_test():\n",
    "    SDnet = DBPN2SSD('dbpn/models/DBPN_x4.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "    net = SDnet\n",
    "    \n",
    "    if cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = True\n",
    "        net = net.cuda()\n",
    "\n",
    "    else:\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "\n",
    "    \n",
    "simple_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor ## UNCOMMENT THIS LINE IF YOU'RE ON A GPU!\n",
    "\n",
    "# Real samples were all associated with Ture labels - 1\n",
    "T_labels = torch.ones(logits_real.size()).type(dtype)\n",
    "# Fake samples were all associated with Fake labels - 0\n",
    "F_labels = torch.zeros(logits_fake.size()).type(dtype)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
