{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The following code is modified based on the original torchcv project. \n",
    "* We are going to use PASACAL VOC12 as dataset.\n",
    "* You could donwload VOC2012 \n",
    "  train/validation: http://host.robots.ox.ac.uk/pascal/VOC/voc2012/#devkit\n",
    "* test data: https://pjreddie.com/projects/pascal-voc-dataset-mirror/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from __future__ import print_function\n",
    "from dbpn import Net as DBPN\n",
    "from dbpn import get_pair_set\n",
    "from ssd import SSD\n",
    "from ssd import build_ssd\n",
    "from ssd.layers.modules import MultiBoxLoss\n",
    "from ssd.data.config import voc\n",
    "from ssd.data import detection_collate\n",
    "from ssd.data import VOCAnnotationTransform, VOCDetection, BaseTransform, SRDetection, DBPNLoader\n",
    "from ssd.eval import test_net\n",
    "from metric import *\n",
    "\n",
    "import sys; sys.argv=['']; del sys\n",
    "\n",
    "# clean up device\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(anno_path='Annotations', batch_size=2, checkpt='./checkpoint', gpu_mode=True, gpus=1, hr_dataset='VOC12-HR', imSetpath='ImageSets', input_dir='./dataset', lr=0.0001, nEpochs=10, seed=123, testBatchSize=1, threads=2, train_dataset='VOC12-LR-x4', upscale_factor=4)\n"
     ]
    }
   ],
   "source": [
    "# Global arguments & settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch Super Resolution Detection Networks')\n",
    "parser.add_argument('--upscale_factor', type=int, default=4, help=\"super resolution upscale factor\")\n",
    "parser.add_argument('--testBatchSize', type=int, default=1, help='testing batch size')\n",
    "parser.add_argument('--batch_size', type=int, default=2, help='training batch size') # GPU: 9GB!\n",
    "parser.add_argument('--threads', type=int, default=2, help='number of threads for data loading')\n",
    "parser.add_argument('--seed', type=int, default=123, help='random seed to use. Default=123')\n",
    "parser.add_argument('--gpu_mode', type=bool, default=True)\n",
    "parser.add_argument('--gpus', default=1, type=float, help='number of gpu')\n",
    "#parser.add_argument('--test_dataset', type=str, default='VOC12-LR-X8-test')\n",
    "#parser.add_argument('--sr_dataset', type=str, default='VOC12-SR-X8')\n",
    "parser.add_argument('--train_dataset', type=str, default='VOC12-LR-x4')\n",
    "parser.add_argument('--hr_dataset', type=str, default='VOC12-HR')\n",
    "parser.add_argument('--anno_path', type=str, default='Annotations')\n",
    "parser.add_argument('--imSetpath', type=str, default='ImageSets')\n",
    "parser.add_argument('--input_dir', type=str, default='./dataset')\n",
    "#parser.add_argument('--output', default='./dataset/results', help='Location to save some outputs')\n",
    "parser.add_argument('--checkpt', default='./checkpoint', help='Location to save checkpoint models')\n",
    "parser.add_argument('--lr', type=float, default=1e-4, help='Learning Rate. Default=0.0001')\n",
    "parser.add_argument('--nEpochs', type=int, default=10, help='number of epochs to fine tune net S over target loss')\n",
    "\n",
    "opt = parser.parse_args()\n",
    "\n",
    "gpus_list=range(opt.gpus)\n",
    "print(opt)\n",
    "\n",
    "cuda = opt.gpu_mode\n",
    "if cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run without --cuda\")\n",
    "\n",
    "torch.manual_seed(opt.seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(opt.seed)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "Epochs = opt.nEpochs\n",
    "tbz = opt.batch_size\n",
    "num_classes = 21           # 20 (VOC0712) +1 for background\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading SSD300 task evaluation network!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x/cs231n/super-resolution-detection/ssd/ssd.py:34: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.priors = Variable(self.priorbox.forward(), volatile=True)\n",
      "/home/x/cs231n/super-resolution-detection/ssd/layers/modules/l2norm.py:17: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.weight,self.gamma)\n"
     ]
    }
   ],
   "source": [
    "# Task validation Setup - We use VOC07 Detection validation for our SROD network\n",
    "\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "voc_root = os.path.join(HOME, \"data/VOCdevkit/\")\n",
    "\n",
    "annopath = os.path.join(voc_root, 'VOC2007', 'Annotations', '%s.xml')\n",
    "imgpath = os.path.join(voc_root, 'VOC2007', 'JPEGImages', '%s.jpg')\n",
    "imgsetpath = os.path.join(voc_root, 'VOC2007', 'ImageSets', 'Main', '{:s}.txt')\n",
    "YEAR = '2007'\n",
    "devkit_path = voc_root + 'VOC' + YEAR\n",
    "# VOC0712 image channel MEANS\n",
    "dataset_mean = (104, 117, 123)\n",
    "\n",
    "# Random picked detection network end-task validation set,\n",
    "# N.B. it is not for SROD (DBPN+SSD) training target Loss.\n",
    "set_type = '07val32-5702'\n",
    "# set_typs is explained below:\n",
    "\"\"\"\n",
    "We have 5 validation sets to choose, size of 16, 32, 64, 128, 256 repectively,\n",
    "Due to the time & computation constraint, we have these 5 downsampled val set.\n",
    "They are randomly(no replacement) picked from  VOC2007/ImageSets/Main/val.txt.\n",
    "\n",
    "Baseline mAP on Pre-trained ssd300 is measured as well:       (mAP)\n",
    "These Detection baseline are measured on frozen SSD300 network using\n",
    "'weights/ssd300_mAP_77.43_v2.pth', for 75x75 LR images been SR-ed by\n",
    "VOC12 retrained DBPN baseline w. weight 'VOC12-LR-x4-DBPN-ep100.pth'.\n",
    "\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val16-5648.txt      56.48%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val32-5702.txt      57.02%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val64-5826.txt      58.26%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val128-6019.txt     60.19%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val256-6030.txt     60.30%\n",
    "\n",
    "These can be used to evaluate training in progress quantatively.\n",
    "Again we do not run through whole val set for periodical check out, too slow!\n",
    "\"\"\"\n",
    "\n",
    "# Utility functions\n",
    "def save_img(img, img_path):\n",
    "    save_img = img.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n",
    "    cv2.imwrite(img_path, cv2.cvtColor(save_img*255, cv2.COLOR_BGR2RGB),  [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "# Dataloader for SuperVision Subnetwork Evaluation\n",
    "eval_set = DBPNLoader(root='./dataset')\n",
    "eval_loader = DataLoader(dataset=eval_set, batch_size=1, num_workers=1, shuffle=False)\n",
    "\n",
    "\n",
    "# Network and Dataloader for Detection subnetwork to End Task Eval\n",
    "# Tried to reuse 2nd half of our SRD net for detection, not lucky!\n",
    "ssd300net = build_ssd('test', 300, num_classes)   # initialize SSD\n",
    "ssd300net.load_state_dict(torch.load('ssd/weights/ssd300_mAP_77.43_v2.pth'))\n",
    "ssd300net.eval()\n",
    "\n",
    "print('Finished loading SSD300 task evaluation network!')\n",
    "eval_det = VOCDetection(voc_root, [('2007', set_type)],\n",
    "                       BaseTransform(300, dataset_mean),\n",
    "                       VOCAnnotationTransform(), sr_path='./dataset/VOC07-SR-x4')\n",
    "if cuda:\n",
    "     ssd300net = ssd300net.cuda()\n",
    "     cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading SRD sub Net-S (DBPN) fine-tune training datasets (VOC12)\n"
     ]
    }
   ],
   "source": [
    "print('===> Loading SRD sub Net-S (DBPN) fine-tune training datasets (VOC12)')\n",
    "\n",
    "sd_dataset = SRDetection(root='./dataset', image_sets='trainval.txt', data_mean = dataset_mean,\n",
    "                         target_transform = VOCAnnotationTransform())\n",
    "\n",
    "sd_data_loader = DataLoader(dataset=sd_dataset, batch_size=opt.batch_size, num_workers=opt.threads,\n",
    "                            shuffle=False, collate_fn=detection_collate, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Architecture Definition of SRD network model: Net-S (DBPN) + Net-D (SSD300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x/cs231n/super-resolution-detection/dbpn/dbpn.py:47: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  torch.nn.init.kaiming_normal(m.weight)\n",
      "/home/x/cs231n/super-resolution-detection/dbpn/dbpn.py:51: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  torch.nn.init.kaiming_normal(m.weight)\n",
      "/home/x/cs231n/super-resolution-detection/ssd/ssd.py:34: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.priors = Variable(self.priorbox.forward(), volatile=True)\n",
      "/home/x/cs231n/super-resolution-detection/ssd/layers/modules/l2norm.py:17: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.weight,self.gamma)\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "# 1. come up with test/eval functions\n",
    "# 2. come up with visualization image\n",
    "\n",
    "print('===> Architecture Definition of SRD network model: Net-S (DBPN) + Net-D (SSD300)')\n",
    "\n",
    "\n",
    "class DBPN2SSD(nn.Module):\n",
    "    \n",
    "    def __init__(self, s_model_name, d_model_name, d_frozen):\n",
    "        super(DBPN2SSD, self).__init__()\n",
    "        self.supervis = DBPN(num_channels=3, base_filter=64, feat=256, num_stages=7, scale_factor=4)\n",
    "        if os.path.exists(s_model_name):\n",
    "            self.supervis = torch.nn.DataParallel(self.supervis, device_ids=gpus_list)\n",
    "            self.supervis.load_state_dict(torch.load(s_model_name, map_location=lambda storage, loc: storage))\n",
    "\n",
    "        # self.detector = SSD(), setup ssd as 'train' mode for gradient flow\n",
    "        # later at test/eval situation, we will overwrite it's mode to 'test'\n",
    "        self.detector = build_ssd('train', 300, num_classes)\n",
    "        if os.path.exists(d_model_name):\n",
    "            self.detector.load_state_dict(torch.load(d_model_name, map_location=lambda storage, loc: storage))\n",
    "        if d_frozen:\n",
    "            for param in self.detector.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        superx = self.supervis(x)\n",
    "        # current detector: SSD300, so assume superx: 300x300!\n",
    "        detect = self.detector(superx)\n",
    "        return (superx, detect)\n",
    "\n",
    "\n",
    "#SDnet = DBPN2SSD('dbpn/models/DBPN_x4.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "#SDnet = DBPN2SSD('checkpoint/SRx4_4000.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "SRDnet = DBPN2SSD('dbpn/models/VOC12-LR-x4-DBPN-ep100.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections\n",
      "0.5011552918037575\n"
     ]
    }
   ],
   "source": [
    "def mAP_eval():\n",
    "    mAP = test_net('./eval', ssd300net, cuda, eval_det, BaseTransform(ssd300net.size, dataset_mean), \\\n",
    "                   5, 300, thresh=0.01, eval_set=set_type)\n",
    "    return mAP\n",
    "    \n",
    "print(mAP_eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main SRD training Loop\n",
    "\n",
    "# Hyperparameters - balancing weights of net S loss vs. net D loss\n",
    "# alpha = 1.0\n",
    "# beta = 1.0\n",
    "\n",
    "Epochs = 2\n",
    "# decay_steps = [5000, 10000, 20000, 40000, 80000] in iterations\n",
    "# decay_steps = [5, 10, 20, 40, 80]              # in epochs\n",
    "# decay_steps = [4, 8]                           # in epochs\n",
    "# experimental: half LR at 3rd epoch\n",
    "decay_steps = [2]                                # in epochs\n",
    "gamma = 0.1\n",
    "def adjust_learning_rate(optimizer, gamma=0.1, step=0):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every\n",
    "        specified step\n",
    "    # Adapted from PyTorch Imagenet example:\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    gamma = 0.5\n",
    "    lr = opt.lr * (gamma ** (step))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return lr\n",
    "\n",
    "# discover 'best' dbpn model according to an eval set\n",
    "best_dbpn_model = None\n",
    "best_val = -1\n",
    "prev_file = None\n",
    "\n",
    "\n",
    "#################################################################\n",
    "#\n",
    "# Parameters:\n",
    "#   alpha  - Loss weight from SuperV Net-S\n",
    "#   beta   - Loss weight from Detect Net-D\n",
    "#   pickle - Pickle file name for all data records\n",
    "#\n",
    "#################################################################\n",
    "def train(SDnet, alpha = 1.0, beta = 1.0, pfname='a100b100.pkl'):\n",
    "    best_val = -1\n",
    "    prev_file = None\n",
    "    \n",
    "    net = SDnet\n",
    "    # current lr\n",
    "    lrt = opt.lr\n",
    "    \n",
    "    # Dictionary to pickle all training/validation data\n",
    "    trainval = {}\n",
    "    \n",
    "    # Following list are appended continously fr. Start2End\n",
    "    # In unit sampling period of each validating invocation.\n",
    "    # total running epochs\n",
    "    epos = []\n",
    "    # total running iterations vs. per epoch\n",
    "    itrs = []\n",
    "    # mean SROD training (compound) losses btw. validation\n",
    "    mlos = []\n",
    "    # mean APs,   sampled at each validation\n",
    "    maps = []\n",
    "    # mean PSNRs, sampled at each validation\n",
    "    mpsn = []\n",
    "    # mean SSIMs, sampled at each validation\n",
    "    msim = []\n",
    "    # current learning rate\n",
    "    clr  = []\n",
    "    \n",
    "\n",
    "    # Criterions:\n",
    "    #\n",
    "    # net SR loss function, change to L2 later\n",
    "    criterion_sr = nn.MSELoss()\n",
    "\n",
    "    # ssd loss function\n",
    "    criterion_ssd = MultiBoxLoss(voc['num_classes'], 0.5, True, 0, True, 3, 0.5, False, use_gpu=cuda)\n",
    "\n",
    "    if cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        #net.supervis = torch.nn.DataParallel(net.supervis)\n",
    "        cudnn.benchmark = True\n",
    "        net = net.cuda(gpus_list[0])\n",
    "        criterion_sr = criterion_sr.cuda(gpus_list[0])\n",
    "        criterion_ssd = criterion_ssd.cuda(gpus_list[0])\n",
    "\n",
    "\n",
    "    # optimizer = optim.SGD(net.supervis.parameters(), lr=opt.lr, \\\n",
    "    #                       momentum=opt.momentum, weight_decay=opt.weight_decay)\n",
    "    #\n",
    "    # Use universal Adam first :)\n",
    "    # we can be Specific to what part of network's parameters to optimize, here is SuperR Net\n",
    "    optimizer = optim.Adam(net.supervis.parameters(), lr=opt.lr, betas=(0.9, 0.999), eps=1e-8)\n",
    "    \n",
    "    # set model to training mode\n",
    "    net.train()\n",
    "    \n",
    "    #epoch = 1\n",
    "    #max_iter = 20000\n",
    "    max_iter  =   600    # Approx. within 1 Epoch 5600/5770\n",
    "    decay_step = 0\n",
    "    for epoch in range(1, Epochs + 1):\n",
    "        t_0 = time()\n",
    "        epoch_loss = 0\n",
    "        iters_loss = 0\n",
    "        for iteration, batch in enumerate(sd_data_loader, 1):\n",
    "\n",
    "            if iteration == max_iter + 1:\n",
    "                break\n",
    "            if epoch in decay_steps and iteration == 1:\n",
    "                decay_step += 1\n",
    "                lrt = adjust_learning_rate(optimizer, gamma, decay_step)\n",
    "\n",
    "            # input is LR image; sr_target is pseudo (300x300) original HR image, det_target is bboxes\n",
    "            input, sr_target, det_target = batch[0], batch[1], batch[2]\n",
    "            if cuda:\n",
    "                input = Variable(input.cuda(gpus_list[0]))\n",
    "                sr_target = Variable(sr_target.cuda(gpus_list[0]))\n",
    "                det_target = [Variable(ann.cuda(gpus_list[0]), volatile=True) for ann in det_target]\n",
    "            else:\n",
    "                input = Variable(input)\n",
    "                sr_target = Variable(sr_target)\n",
    "                det_target = [Variable(ann, volatile=True) for ann in det_target]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            t0 = time()\n",
    "\n",
    "            sr_out,ssd_out = net(input)\n",
    "            loss_sr = criterion_sr(sr_out, sr_target)\n",
    "\n",
    "            # Compound Loss from net-S: loss_sr and net-D: loss_l, loss_c\n",
    "            loss_l, loss_c = criterion_ssd(ssd_out, det_target)\n",
    "            loss = loss_sr * alpha + beta *(loss_l + loss_c)\n",
    "\n",
    "            epoch_loss += loss.data[0]\n",
    "            iters_loss += loss.data[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            t1 = time()\n",
    "\n",
    "            if iteration != 0 and iteration % 20 == 0:\n",
    "                print(\"===> Epoch[{}]({}/{}): Loss: {:.4f} || Time: {:.4f} sec.\".format(epoch, \\\n",
    "                            iteration, len(sd_data_loader), loss.data[0], (t1 - t0)))\n",
    "\n",
    "            # End Task (detection) & Imaging Quality Evaluation vs. Model Loss steps below:\n",
    "            if iteration != 0 and iteration % 200 == 0:\n",
    "                mItersLoss = iters_loss / 200\n",
    "                iters_loss = 0\n",
    "                net.eval()\n",
    "                t2 = time()\n",
    "                i, ssim, psnr  = 0, 0, 0\n",
    "                for iter, bat in enumerate(eval_loader, 1):\n",
    "                    # loader output:  lr,     hr,   fname\n",
    "                    lr, hr, fname = bat[0], bat[1], bat[2]\n",
    "                    # lr, hr, fname = eval_set.pull_item(i)\n",
    "                    if cuda:\n",
    "                        lr_v = Variable(lr.cuda(gpus_list[0]))\n",
    "                    else:\n",
    "                        lr_v = Variable(lr)\n",
    "                    sr, _ = net(lr_v)\n",
    "                    srimg = sr.cpu().data\n",
    "                    hrimg = hr.data\n",
    "\n",
    "                    # Struct Similarity Index & Peak Signal-Noise Ratio\n",
    "                    ssim += metric_ssim(hrimg.numpy(), srimg.numpy())\n",
    "                    psnr += metric_psnr(hrimg.numpy(), srimg.numpy())\n",
    "                    i += 1\n",
    "                    #print(\"ssim, psnr:\", ssim, psnr)\n",
    "\n",
    "                    image=srimg\n",
    "                    image = (image - image.min())/(image.max() - image.min())\n",
    "                    imagef = os.path.join('./dataset/VOC07-SR-x4/', '%s.jpg')\n",
    "                    save_img(image, imagef % fname)\n",
    "\n",
    "                mSSIM = ssim / i\n",
    "                mPSNR = psnr / i\n",
    "                mAP_acc = mAP_eval()\n",
    "                t3 = time()\n",
    "                print(\"Mean Loss = {:.4f}, Mean AP = {:.4f}, Mean SSIM = {:.4f}, Mean PSNR = {:.4f} || Time: {:.4f} sec.\"\\\n",
    "                      .format(mItersLoss, mAP_acc, mSSIM, mPSNR, (t3 - t2)))\n",
    "\n",
    "                # Updating lists to be pickled\n",
    "                epos.append(epoch)\n",
    "                itrs.append(iteration + max_iter*(epoch-1))\n",
    "                mlos.append(float(mItersLoss))\n",
    "                maps.append(mAP_acc)\n",
    "                mpsn.append(mPSNR)\n",
    "                msim.append(mSSIM)\n",
    "                clr.append(lrt)\n",
    "\n",
    "                mAP_int = int(mAP_acc * 10000)     #  2318 =>  23.18 %\n",
    "                mPSNR_i = int(mPSNR * 100)         #  2318 =>  23.18 dB\n",
    "                if math.isnan(mSSIM):\n",
    "                    mSSIM_i = 'NaN'\n",
    "                else:\n",
    "                    mSSIM_i = int(mSSIM * 10000)   #  2318 => 0.2318\n",
    "                if mAP_int > best_val:\n",
    "                    best_val = mAP_int\n",
    "                    if prev_file is not None:\n",
    "                        os.remove(prev_file)\n",
    "                    chkfile = opt.checkpt + '/' + 'SRx4_e' + repr(epoch) + '_i' + repr(iteration) + \\\n",
    "                              '_mAP' + repr(best_val) + '_mPSNR' + repr(mPSNR_i) + '_mSSIM' + repr(mSSIM_i) + '.pth'\n",
    "                    torch.save(net.supervis.state_dict(), chkfile)\n",
    "                    prev_file = chkfile\n",
    "\n",
    "                # back to training mode\n",
    "                net.train()\n",
    "\n",
    "            if iteration != 0 and iteration % 2000 == 0:\n",
    "                print('Saving state, iter:', iteration)\n",
    "                torch.save(net.supervis.state_dict(), opt.checkpt + '/' + 'SRx4_' + repr(iteration+4000) + '.pth')\n",
    "        t_1 = time()\n",
    "        print(\"===> Epoch {} Complete: Avg. Loss: {:.4f} || Time: {:.4f} sec.\"\\\n",
    "              .format(epoch, epoch_loss / (max_iter * tbz), (t_1 - t_0)))\n",
    "\n",
    "    # pickle all the data records\n",
    "    trainval['epochs'] = epos\n",
    "    trainval['iters'] = itrs\n",
    "    trainval['mloss'] = mlos\n",
    "    trainval['m_aps'] = maps\n",
    "    trainval['mpsnr'] = mpsn\n",
    "    trainval['mssim'] = msim\n",
    "    trainval['lrate'] = clr\n",
    "    with open(pfname, 'wb') as f:\n",
    "        pickle.dump(trainval, f)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__:117: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "__main__:133: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "__main__:134: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "__main__:140: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[1](20/5770): Loss: 2775.5461 || Time: 0.3392 sec.\n",
      "===> Epoch[1](40/5770): Loss: 2012.5754 || Time: 0.3478 sec.\n",
      "===> Epoch[1](60/5770): Loss: 1785.6118 || Time: 0.3460 sec.\n",
      "===> Epoch[1](80/5770): Loss: 1393.4235 || Time: 0.3319 sec.\n",
      "===> Epoch[1](100/5770): Loss: 1373.8630 || Time: 0.3375 sec.\n",
      "===> Epoch[1](120/5770): Loss: 911.0864 || Time: 0.3413 sec.\n",
      "===> Epoch[1](140/5770): Loss: 1561.3210 || Time: 0.3486 sec.\n",
      "===> Epoch[1](160/5770): Loss: 1358.3650 || Time: 0.3312 sec.\n",
      "===> Epoch[1](180/5770): Loss: 1492.9572 || Time: 0.3441 sec.\n",
      "===> Epoch[1](200/5770): Loss: 564.3323 || Time: 0.3306 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x/cs231n/super-resolution-detection/metric.py:188: RuntimeWarning: invalid value encountered in power\n",
      "  return (np.prod(mcs[0:levels - 1]**weights[0:levels - 1]) *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections\n",
      "Mean Loss = 3403.0847, Mean AP = -0.0053, Mean SSIM = nan, Mean PSNR = 19.0337 || Time: 11.0813 sec.\n",
      "===> Epoch[1](220/5770): Loss: 751.6975 || Time: 0.3542 sec.\n",
      "===> Epoch[1](240/5770): Loss: 1069.4471 || Time: 0.3336 sec.\n",
      "===> Epoch[1](260/5770): Loss: 952.1415 || Time: 0.3513 sec.\n",
      "===> Epoch[1](280/5770): Loss: 468.7316 || Time: 0.3470 sec.\n",
      "===> Epoch[1](300/5770): Loss: 998.2669 || Time: 0.3516 sec.\n",
      "===> Epoch[1](320/5770): Loss: 619.3965 || Time: 0.3423 sec.\n",
      "===> Epoch[1](340/5770): Loss: 628.1650 || Time: 0.3326 sec.\n",
      "===> Epoch[1](360/5770): Loss: 931.2533 || Time: 0.3288 sec.\n",
      "===> Epoch[1](380/5770): Loss: 734.4723 || Time: 0.3527 sec.\n",
      "===> Epoch[1](400/5770): Loss: 802.0309 || Time: 0.3287 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 841.2629, Mean AP = 0.3313, Mean SSIM = 0.8113, Mean PSNR = 20.4841 || Time: 10.4097 sec.\n",
      "===> Epoch[1](420/5770): Loss: 412.8867 || Time: 0.3468 sec.\n",
      "===> Epoch[1](440/5770): Loss: 1331.4495 || Time: 0.3357 sec.\n",
      "===> Epoch[1](460/5770): Loss: 359.9132 || Time: 0.3395 sec.\n",
      "===> Epoch[1](480/5770): Loss: 495.3428 || Time: 0.3299 sec.\n",
      "===> Epoch[1](500/5770): Loss: 814.6560 || Time: 0.3429 sec.\n",
      "===> Epoch[1](520/5770): Loss: 536.9738 || Time: 0.3338 sec.\n",
      "===> Epoch[1](540/5770): Loss: 554.7619 || Time: 0.3345 sec.\n",
      "===> Epoch[1](560/5770): Loss: 557.9844 || Time: 0.3682 sec.\n",
      "===> Epoch[1](580/5770): Loss: 682.6741 || Time: 0.3415 sec.\n",
      "===> Epoch[1](600/5770): Loss: 162.3298 || Time: 0.3277 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 578.8281, Mean AP = 0.3774, Mean SSIM = 0.8813, Mean PSNR = 21.4473 || Time: 10.4887 sec.\n",
      "===> Epoch 1 Complete: Avg. Loss: 803.8625 || Time: 241.1971 sec.\n",
      "===> Epoch[2](20/5770): Loss: 290.3421 || Time: 0.3440 sec.\n",
      "===> Epoch[2](40/5770): Loss: 220.4613 || Time: 0.3459 sec.\n",
      "===> Epoch[2](60/5770): Loss: 538.9113 || Time: 0.3271 sec.\n",
      "===> Epoch[2](80/5770): Loss: 348.8078 || Time: 0.3347 sec.\n",
      "===> Epoch[2](100/5770): Loss: 595.3157 || Time: 0.3378 sec.\n",
      "===> Epoch[2](120/5770): Loss: 255.6969 || Time: 0.3443 sec.\n",
      "===> Epoch[2](140/5770): Loss: 748.5032 || Time: 0.3278 sec.\n",
      "===> Epoch[2](160/5770): Loss: 495.9378 || Time: 0.3589 sec.\n",
      "===> Epoch[2](180/5770): Loss: 500.7381 || Time: 0.3546 sec.\n",
      "===> Epoch[2](200/5770): Loss: 325.9262 || Time: 0.3293 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 432.5773, Mean AP = 0.4425, Mean SSIM = 0.9196, Mean PSNR = 22.4698 || Time: 10.3855 sec.\n",
      "===> Epoch[2](220/5770): Loss: 205.5087 || Time: 0.3368 sec.\n",
      "===> Epoch[2](240/5770): Loss: 436.2156 || Time: 0.3381 sec.\n",
      "===> Epoch[2](260/5770): Loss: 422.3851 || Time: 0.3433 sec.\n",
      "===> Epoch[2](280/5770): Loss: 226.2962 || Time: 0.3376 sec.\n",
      "===> Epoch[2](300/5770): Loss: 278.8497 || Time: 0.3292 sec.\n",
      "===> Epoch[2](320/5770): Loss: 287.5644 || Time: 0.3308 sec.\n",
      "===> Epoch[2](340/5770): Loss: 363.1714 || Time: 0.3325 sec.\n",
      "===> Epoch[2](360/5770): Loss: 421.2323 || Time: 0.3443 sec.\n",
      "===> Epoch[2](380/5770): Loss: 372.3488 || Time: 0.3300 sec.\n",
      "===> Epoch[2](400/5770): Loss: 514.4711 || Time: 0.3497 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 401.7162, Mean AP = 0.4865, Mean SSIM = 0.9211, Mean PSNR = 22.6352 || Time: 10.4127 sec.\n",
      "===> Epoch[2](420/5770): Loss: 226.2066 || Time: 0.3278 sec.\n",
      "===> Epoch[2](440/5770): Loss: 745.3765 || Time: 0.3316 sec.\n",
      "===> Epoch[2](460/5770): Loss: 269.2290 || Time: 0.3328 sec.\n",
      "===> Epoch[2](480/5770): Loss: 156.7907 || Time: 0.3311 sec.\n",
      "===> Epoch[2](500/5770): Loss: 718.1862 || Time: 0.3287 sec.\n",
      "===> Epoch[2](520/5770): Loss: 365.6099 || Time: 0.3607 sec.\n",
      "===> Epoch[2](540/5770): Loss: 436.8902 || Time: 0.3275 sec.\n",
      "===> Epoch[2](560/5770): Loss: 327.1866 || Time: 0.3290 sec.\n",
      "===> Epoch[2](580/5770): Loss: 532.2073 || Time: 0.3411 sec.\n",
      "===> Epoch[2](600/5770): Loss: 116.2842 || Time: 0.3322 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 382.6595, Mean AP = 0.4769, Mean SSIM = 0.9202, Mean PSNR = 22.6347 || Time: 10.1641 sec.\n",
      "===> Epoch 2 Complete: Avg. Loss: 202.8255 || Time: 234.8407 sec.\n"
     ]
    }
   ],
   "source": [
    "# SROD Compund Loss relative ratio, Net-S vs. Net-D\n",
    "# Alpha is weight Loss from Net-S (e.g. DBPN) Loss\n",
    "# Beta  is weight Loss from Net-D (e.g. SSD ) Loss\n",
    "AlphaBeta = [(1.00, 0.01),   (1.00, 0.10),   (1.00, 1.00),   (0.10, 1.00),   (0.01, 1.00)]\n",
    "pickle_fs = ['a100b001.pkl', 'a100b010.pkl', 'a100b100.pkl', 'a010b100.pkl', 'a001b100.pkl']\n",
    "\n",
    "a, b = AlphaBeta[0]\n",
    "pf = pickle_fs[0]\n",
    "\n",
    "train(SRDnet, a, b, pf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpickle data records for visual\n",
    "with open(pf, 'rb') as f:\n",
    "    trainval = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging code below, no need to run :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' YOU Donot need to run this ===> Loading some datasets')\n",
    "\n",
    "lr_path = os.path.join(opt.input_dir, opt.train_dataset)\n",
    "hr_path = os.path.join(opt.input_dir, opt.hr_dataset)\n",
    "\n",
    "fine_train_set = get_pair_set(lr_path, hr_path)\n",
    "train_data_loader = DataLoader(dataset=fine_train_set, num_workers=opt.threads, \\\n",
    "                               batch_size=opt.testBatchSize, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_test():\n",
    "    SDnet = DBPN2SSD('dbpn/models/DBPN_x4.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "    net = SDnet\n",
    "    \n",
    "    if cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = True\n",
    "        net = net.cuda()\n",
    "\n",
    "    else:\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "\n",
    "    \n",
    "simple_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor ## UNCOMMENT THIS LINE IF YOU'RE ON A GPU!\n",
    "\n",
    "# Real samples were all associated with Ture labels - 1\n",
    "T_labels = torch.ones(logits_real.size()).type(dtype)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
