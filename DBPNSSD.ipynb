{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The following code is modified based on the original torchcv project. \n",
    "* We are going to use PASACAL VOC12 as dataset.\n",
    "* You could donwload VOC2012 \n",
    "  train/validation: http://host.robots.ox.ac.uk/pascal/VOC/voc2012/#devkit\n",
    "* test data: https://pjreddie.com/projects/pascal-voc-dataset-mirror/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from __future__ import print_function\n",
    "from dbpn import Net as DBPN\n",
    "from dbpn import get_pair_set\n",
    "from ssd import SSD\n",
    "from ssd import build_ssd\n",
    "from ssd.layers.modules import MultiBoxLoss\n",
    "from ssd.data.config import voc\n",
    "from ssd.data import detection_collate\n",
    "from ssd.data import VOCAnnotationTransform, VOCDetection, BaseTransform, SRDetection\n",
    "\n",
    "import sys; sys.argv=['']; del sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(anno_path='Annotations', batch_size=2, gpu_mode=True, gpus=1, hr_dataset='VOC12-HR', imSetpath='ImageSets', input_dir='./dataset', lr=0.0001, nEpochs=20, output='./dataset/results', seed=123, sr_dataset='VOC12-SR-X8', testBatchSize=1, test_dataset='VOC12-LR-X8-test', threads=4, train_dataset='VOC12-LR-X8', upscale_factor=8)\n"
     ]
    }
   ],
   "source": [
    "# Arguments & settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch Super Resolution Detection Networks')\n",
    "parser.add_argument('--upscale_factor', type=int, default=8, help=\"super resolution upscale factor\")\n",
    "parser.add_argument('--testBatchSize', type=int, default=1, help='testing batch size')\n",
    "parser.add_argument('--batch_size', type=int, default=2, help='training batch size')\n",
    "parser.add_argument('--threads', type=int, default=4, help='number of threads for data loading')\n",
    "parser.add_argument('--seed', type=int, default=123, help='random seed to use. Default=123')\n",
    "parser.add_argument('--gpu_mode', type=bool, default=True)\n",
    "parser.add_argument('--gpus', default=1, type=float, help='number of gpu')\n",
    "parser.add_argument('--test_dataset', type=str, default='VOC12-LR-X8-test')\n",
    "parser.add_argument('--train_dataset', type=str, default='VOC12-LR-X8')\n",
    "parser.add_argument('--sr_dataset', type=str, default='VOC12-SR-X8')\n",
    "parser.add_argument('--hr_dataset', type=str, default='VOC12-HR')\n",
    "parser.add_argument('--anno_path', type=str, default='Annotations')\n",
    "parser.add_argument('--imSetpath', type=str, default='ImageSets')\n",
    "parser.add_argument('--input_dir', type=str, default='./dataset')\n",
    "parser.add_argument('--output', default='./dataset/results', help='Location to save checkpoint models')\n",
    "parser.add_argument('--lr', type=float, default=1e-4, help='Learning Rate. Default=0.0001')\n",
    "parser.add_argument('--nEpochs', type=int, default=20, help='number of epochs to fine tune net S over target loss')\n",
    "\n",
    "opt = parser.parse_args()\n",
    "\n",
    "gpus_list=range(opt.gpus)\n",
    "print(opt)\n",
    "\n",
    "cuda = opt.gpu_mode\n",
    "if cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run without --cuda\")\n",
    "\n",
    "torch.manual_seed(opt.seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(opt.seed)\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading net S fine-tune training datasets\n"
     ]
    }
   ],
   "source": [
    "print('===> Loading net S fine-tune training datasets')\n",
    "# VOC0712 dataset mean\n",
    "MEANS = (104, 117, 123)\n",
    "\n",
    "sd_dataset = SRDetection(root='./dataset', image_sets='trainval.txt', data_mean = MEANS,\n",
    "                         target_transform = VOCAnnotationTransform())\n",
    "\n",
    "sd_data_loader = DataLoader(dataset=sd_dataset, batch_size=opt.batch_size, num_workers=opt.threads,\n",
    "                            shuffle=False, collate_fn=detection_collate, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# 1. come up with test/eval functions\n",
    "# 2. come up with visualization image\n",
    "\n",
    "class DBPN2SSD(nn.Module):\n",
    "    \n",
    "    def __init__(self, s_model_name, d_model_name, d_frozen):\n",
    "        super(DBPN2SSD, self).__init__()\n",
    "        self.supervis = DBPN(num_channels=3, base_filter=64, feat=256, num_stages=7, scale_factor=4)\n",
    "        if os.path.exists(s_model_name):\n",
    "            self.supervis = torch.nn.DataParallel(self.supervis)\n",
    "            self.supervis.load_state_dict(torch.load(s_model_name, map_location=lambda storage, loc: storage))\n",
    "\n",
    "        # self.detector = SSD(), setup ssd as 'train' mode for gradient flow\n",
    "        # later at test/eval situation, we will overwrite it's mode to 'test'\n",
    "        self.detector = build_ssd('train', 300, 21)\n",
    "        if os.path.exists(d_model_name):\n",
    "            self.detector.load_state_dict(torch.load(d_model_name, map_location=lambda storage, loc: storage))\n",
    "        if d_frozen:\n",
    "            for param in self.detector.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        superx = self.supervis(x)\n",
    "        # current detector: SSD300, so assume superx: 300x300!\n",
    "        detect = self.detector(superx)\n",
    "        return (superx, detect)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.0\n",
    "beta = 1.0\n",
    "\n",
    "def train():\n",
    "    SDnet = DBPN2SSD('dbpn/models/DBPN_x4.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "    net = SDnet\n",
    "    \n",
    "    if cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        net.supervis = torch.nn.DataParallel(net.supervis)\n",
    "        cudnn.benchmark = True\n",
    "        net = net.cuda()\n",
    "\n",
    "    # we can be Specific to what part parameters to optimize\n",
    "    optimizer = optim.Adam(net.supervis.parameters(), lr=opt.lr, betas=(0.9, 0.999), eps=1e-8)\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # set model to training mode\n",
    "    net.train()\n",
    "    \n",
    "    # ssd loss function\n",
    "    criterion_ssd = MultiBoxLoss(voc['num_classes'], 0.5, True, 0, True, 3, 0.5, False, cuda).cuda()\n",
    "    \n",
    "    # net SR loss function, change to L2 later\n",
    "    criterion_sr = nn.L1Loss().cuda()\n",
    "    \n",
    "    epoch = 1\n",
    "    \n",
    "    for iteration, batch in enumerate(sd_data_loader, 1):\n",
    "        # input is LR image; sr_target is pseudo (300x300) original HR image, det_target is bboxes\n",
    "        # input, sr_target, det_target = Variable(batch[0]), Variable(batch[1]), Variable(torch.FloatTensor(batch[2]))\n",
    "        input, sr_target, det_target = Variable(batch[0]), Variable(batch[1]), batch[2]\n",
    "\n",
    "        if cuda:\n",
    "            input = input.cuda(gpus_list[0])\n",
    "            sr_target = sr_target.cuda(gpus_list[0])\n",
    "            #det_target = det_target.cuda(gpus_list[0])\n",
    "\n",
    "            #det_target = [Variable(ann.cuda(gpus_list[0]), volatile=True) for ann in det_target]\n",
    "            det_target = [Variable(ann.cuda(gpus_list[0], async=True), volatile=True) for ann in det_target]\n",
    "            #det_target = det_target.cuda(gpus_list[0])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        t0 = time()\n",
    "        \n",
    "        sr_out,ssd_out = net(input)\n",
    "        loss_sr = criterion_sr(sr_out, sr_target)\n",
    "        \n",
    "        # TODO: need code up detector's output - targets\n",
    "        loss_l, loss_c = criterion_ssd(ssd_out, det_target)\n",
    "        loss = loss_sr * alpha + beta *(loss_l + loss_c)\n",
    "        \n",
    "        t1 = time()\n",
    "        epoch_loss += loss.data[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"===> Epoch[{}]({}/{}): Loss: {:.4f} || Timer: {:.4f} sec.\".format(epoch, \\\n",
    "                    iteration, len(sd_data_loader), loss.data[0], (t1 - t0)))\n",
    "\n",
    "        if iteration == 100:\n",
    "            break\n",
    "    \n",
    "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(sd_data_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x/cs231n/super-resolution-detection/dbpn/dbpn.py:47: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  torch.nn.init.kaiming_normal(m.weight)\n",
      "/home/x/cs231n/super-resolution-detection/dbpn/dbpn.py:51: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  torch.nn.init.kaiming_normal(m.weight)\n",
      "/home/x/cs231n/super-resolution-detection/ssd/ssd.py:34: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.priors = Variable(self.priorbox.forward(), volatile=True)\n",
      "/home/x/cs231n/super-resolution-detection/ssd/layers/modules/l2norm.py:17: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.weight,self.gamma)\n",
      "__main__:40: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "__main__:54: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "__main__:58: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[1](1/5770): Loss: 1212.6365 || Timer: 0.1114 sec.\n",
      "===> Epoch[1](2/5770): Loss: 742.5327 || Timer: 0.1087 sec.\n",
      "===> Epoch[1](3/5770): Loss: 369.8475 || Timer: 0.1085 sec.\n",
      "===> Epoch[1](4/5770): Loss: 151.5091 || Timer: 0.1087 sec.\n",
      "===> Epoch[1](5/5770): Loss: 172.2407 || Timer: 0.1087 sec.\n",
      "===> Epoch[1](6/5770): Loss: 201.8983 || Timer: 0.1092 sec.\n",
      "===> Epoch[1](7/5770): Loss: 100.0623 || Timer: 0.1087 sec.\n",
      "===> Epoch[1](8/5770): Loss: 107.8729 || Timer: 0.1100 sec.\n",
      "===> Epoch[1](9/5770): Loss: 56.3826 || Timer: 0.1105 sec.\n",
      "===> Epoch[1](10/5770): Loss: 80.3849 || Timer: 0.1087 sec.\n",
      "===> Epoch[1](11/5770): Loss: 101.6088 || Timer: 0.1090 sec.\n",
      "===> Epoch[1](12/5770): Loss: 72.8212 || Timer: 0.1086 sec.\n",
      "===> Epoch[1](13/5770): Loss: 76.7411 || Timer: 0.1090 sec.\n",
      "===> Epoch[1](14/5770): Loss: 58.1287 || Timer: 0.1087 sec.\n",
      "===> Epoch[1](15/5770): Loss: 63.0724 || Timer: 0.1089 sec.\n",
      "===> Epoch[1](16/5770): Loss: 114.8830 || Timer: 0.1089 sec.\n",
      "===> Epoch[1](17/5770): Loss: 81.4348 || Timer: 0.1088 sec.\n",
      "===> Epoch[1](18/5770): Loss: 103.5473 || Timer: 0.1097 sec.\n",
      "===> Epoch[1](19/5770): Loss: 55.7097 || Timer: 0.1088 sec.\n",
      "===> Epoch[1](20/5770): Loss: 64.5425 || Timer: 0.1214 sec.\n",
      "===> Epoch[1](21/5770): Loss: 60.5094 || Timer: 0.1089 sec.\n",
      "===> Epoch[1](22/5770): Loss: 75.7059 || Timer: 0.1086 sec.\n",
      "===> Epoch[1](23/5770): Loss: 52.3893 || Timer: 0.1090 sec.\n",
      "===> Epoch[1](24/5770): Loss: 58.6846 || Timer: 0.1120 sec.\n",
      "===> Epoch[1](25/5770): Loss: 40.7102 || Timer: 0.1087 sec.\n",
      "===> Epoch[1](26/5770): Loss: 62.6248 || Timer: 0.1088 sec.\n",
      "===> Epoch[1](27/5770): Loss: 51.7907 || Timer: 0.1088 sec.\n",
      "===> Epoch[1](28/5770): Loss: 39.0910 || Timer: 0.1090 sec.\n",
      "===> Epoch[1](29/5770): Loss: 56.5792 || Timer: 0.1088 sec.\n",
      "===> Epoch[1](30/5770): Loss: 49.7983 || Timer: 0.1090 sec.\n",
      "===> Epoch[1](31/5770): Loss: 32.9157 || Timer: 0.1105 sec.\n",
      "===> Epoch[1](32/5770): Loss: 44.1324 || Timer: 0.1092 sec.\n",
      "===> Epoch[1](33/5770): Loss: 61.4206 || Timer: 0.1088 sec.\n",
      "===> Epoch[1](34/5770): Loss: 47.0461 || Timer: 0.1089 sec.\n",
      "===> Epoch[1](35/5770): Loss: 35.5049 || Timer: 0.1357 sec.\n",
      "===> Epoch[1](36/5770): Loss: 57.7392 || Timer: 0.1095 sec.\n",
      "===> Epoch[1](37/5770): Loss: 47.5349 || Timer: 0.1093 sec.\n",
      "===> Epoch[1](38/5770): Loss: 25.0685 || Timer: 0.1209 sec.\n",
      "===> Epoch[1](39/5770): Loss: 47.3227 || Timer: 0.1093 sec.\n",
      "===> Epoch[1](40/5770): Loss: 40.7881 || Timer: 0.1231 sec.\n",
      "===> Epoch[1](41/5770): Loss: 37.5042 || Timer: 0.1092 sec.\n",
      "===> Epoch[1](42/5770): Loss: 67.3795 || Timer: 0.1090 sec.\n",
      "===> Epoch[1](43/5770): Loss: 33.0311 || Timer: 0.1244 sec.\n",
      "===> Epoch[1](44/5770): Loss: 30.7594 || Timer: 0.1120 sec.\n",
      "===> Epoch[1](45/5770): Loss: 34.3564 || Timer: 0.1091 sec.\n",
      "===> Epoch[1](46/5770): Loss: 42.1247 || Timer: 0.1092 sec.\n",
      "===> Epoch[1](47/5770): Loss: 35.4704 || Timer: 0.1093 sec.\n",
      "===> Epoch[1](48/5770): Loss: 48.1824 || Timer: 0.1094 sec.\n",
      "===> Epoch[1](49/5770): Loss: 28.0122 || Timer: 0.1092 sec.\n",
      "===> Epoch[1](50/5770): Loss: 33.6272 || Timer: 0.1094 sec.\n",
      "===> Epoch[1](51/5770): Loss: 57.1035 || Timer: 0.1113 sec.\n",
      "===> Epoch[1](52/5770): Loss: 43.2176 || Timer: 0.1112 sec.\n",
      "===> Epoch[1](53/5770): Loss: 31.8281 || Timer: 0.1093 sec.\n",
      "===> Epoch[1](54/5770): Loss: 31.7990 || Timer: 0.1093 sec.\n",
      "===> Epoch[1](55/5770): Loss: 41.5890 || Timer: 0.1095 sec.\n",
      "===> Epoch[1](56/5770): Loss: 31.9732 || Timer: 0.1113 sec.\n",
      "===> Epoch[1](57/5770): Loss: 33.8620 || Timer: 0.1091 sec.\n",
      "===> Epoch[1](58/5770): Loss: 39.7264 || Timer: 0.1094 sec.\n",
      "===> Epoch[1](59/5770): Loss: 24.7031 || Timer: 0.1093 sec.\n",
      "===> Epoch[1](60/5770): Loss: 40.5009 || Timer: 0.1093 sec.\n",
      "===> Epoch[1](61/5770): Loss: 37.3237 || Timer: 0.1094 sec.\n",
      "===> Epoch[1](62/5770): Loss: 30.7739 || Timer: 0.1094 sec.\n",
      "===> Epoch[1](63/5770): Loss: 29.8094 || Timer: 0.1094 sec.\n",
      "===> Epoch[1](64/5770): Loss: 32.4103 || Timer: 0.1095 sec.\n",
      "===> Epoch[1](65/5770): Loss: 38.1229 || Timer: 0.1096 sec.\n",
      "===> Epoch[1](66/5770): Loss: 36.3028 || Timer: 0.1096 sec.\n",
      "===> Epoch[1](67/5770): Loss: 35.7059 || Timer: 0.1096 sec.\n",
      "===> Epoch[1](68/5770): Loss: 31.8905 || Timer: 0.1123 sec.\n",
      "===> Epoch[1](69/5770): Loss: 31.6789 || Timer: 0.1097 sec.\n",
      "===> Epoch[1](70/5770): Loss: 30.1762 || Timer: 0.1098 sec.\n",
      "===> Epoch[1](71/5770): Loss: 47.7143 || Timer: 0.1095 sec.\n",
      "===> Epoch[1](72/5770): Loss: 43.7923 || Timer: 0.1096 sec.\n",
      "===> Epoch[1](73/5770): Loss: 33.8353 || Timer: 0.1096 sec.\n",
      "===> Epoch[1](74/5770): Loss: 23.6618 || Timer: 0.1097 sec.\n",
      "===> Epoch[1](75/5770): Loss: 36.4976 || Timer: 0.1098 sec.\n",
      "===> Epoch[1](76/5770): Loss: 45.6179 || Timer: 0.1096 sec.\n",
      "===> Epoch[1](77/5770): Loss: 50.1666 || Timer: 0.1095 sec.\n",
      "===> Epoch[1](78/5770): Loss: 33.9810 || Timer: 0.1095 sec.\n",
      "===> Epoch[1](79/5770): Loss: 26.4232 || Timer: 0.1135 sec.\n",
      "===> Epoch[1](80/5770): Loss: 21.0011 || Timer: 0.1094 sec.\n",
      "===> Epoch[1](81/5770): Loss: 37.7655 || Timer: 0.1097 sec.\n",
      "===> Epoch[1](82/5770): Loss: 31.8200 || Timer: 0.1095 sec.\n",
      "===> Epoch[1](83/5770): Loss: 32.5803 || Timer: 0.1095 sec.\n",
      "===> Epoch[1](84/5770): Loss: 35.0617 || Timer: 0.1094 sec.\n",
      "===> Epoch[1](85/5770): Loss: 25.8343 || Timer: 0.1097 sec.\n",
      "===> Epoch[1](86/5770): Loss: 34.5326 || Timer: 0.1094 sec.\n",
      "===> Epoch[1](87/5770): Loss: 33.9032 || Timer: 0.1095 sec.\n",
      "===> Epoch[1](88/5770): Loss: 36.5430 || Timer: 0.1094 sec.\n",
      "===> Epoch[1](89/5770): Loss: 29.2610 || Timer: 0.1096 sec.\n",
      "===> Epoch[1](90/5770): Loss: 29.9842 || Timer: 0.1093 sec.\n",
      "===> Epoch[1](91/5770): Loss: 25.5396 || Timer: 0.1094 sec.\n",
      "===> Epoch[1](92/5770): Loss: 36.6478 || Timer: 0.1094 sec.\n",
      "===> Epoch[1](93/5770): Loss: 30.6066 || Timer: 0.1119 sec.\n",
      "===> Epoch[1](94/5770): Loss: 28.0825 || Timer: 0.1098 sec.\n",
      "===> Epoch[1](95/5770): Loss: 28.0028 || Timer: 0.1095 sec.\n",
      "===> Epoch[1](96/5770): Loss: 22.6541 || Timer: 0.1114 sec.\n",
      "===> Epoch[1](97/5770): Loss: 31.9841 || Timer: 0.1097 sec.\n",
      "===> Epoch[1](98/5770): Loss: 24.9270 || Timer: 0.1095 sec.\n",
      "===> Epoch[1](99/5770): Loss: 29.9305 || Timer: 0.1094 sec.\n",
      "===> Epoch[1](100/5770): Loss: 36.3953 || Timer: 0.1099 sec.\n",
      "===> Epoch 1 Complete: Avg. Loss: 1.2237\n"
     ]
    }
   ],
   "source": [
    "train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging code below, no need to run :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' YOU Donot need to run this ===> Loading some datasets')\n",
    "\n",
    "lr_path = os.path.join(opt.input_dir, opt.train_dataset)\n",
    "hr_path = os.path.join(opt.input_dir, opt.hr_dataset)\n",
    "\n",
    "fine_train_set = get_pair_set(lr_path, hr_path)\n",
    "train_data_loader = DataLoader(dataset=fine_train_set, num_workers=opt.threads, \\\n",
    "                               batch_size=opt.testBatchSize, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_test():\n",
    "    SDnet = DBPN2SSD('dbpn/models/DBPN_x4.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "    net = SDnet\n",
    "    \n",
    "    if cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = True\n",
    "        net = net.cuda()\n",
    "\n",
    "    else:\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "\n",
    "    \n",
    "simple_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
