{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The following code is modified based on the original torchcv project. \n",
    "* We are going to use PASACAL VOC12 as dataset.\n",
    "* You could donwload VOC2012 \n",
    "  train/validation: http://host.robots.ox.ac.uk/pascal/VOC/voc2012/#devkit\n",
    "* test data: https://pjreddie.com/projects/pascal-voc-dataset-mirror/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from __future__ import print_function\n",
    "from dbpn import Net as DBPN\n",
    "from dbpn import get_pair_set\n",
    "from ssd import SSD\n",
    "from ssd import build_ssd\n",
    "from ssd.layers.modules import MultiBoxLoss\n",
    "from ssd.data.config import voc\n",
    "from ssd.data import detection_collate\n",
    "from ssd.data import VOCAnnotationTransform, VOCDetection, BaseTransform, SRDetection, DBPNLoader\n",
    "from ssd.eval import test_net\n",
    "from metric import *\n",
    "\n",
    "import sys; sys.argv=['']; del sys\n",
    "\n",
    "# clean up device\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(anno_path='Annotations', batch_size=2, checkpt='./checkpoint', gpu_mode=True, gpus=1, hr_dataset='VOC12-HR', imSetpath='ImageSets', input_dir='./dataset', lr=0.0001, nEpochs=5, seed=123, testBatchSize=1, threads=2, train_dataset='VOC12-LR-x4', upscale_factor=4)\n"
     ]
    }
   ],
   "source": [
    "# Global arguments & settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch Super Resolution Detection Networks')\n",
    "parser.add_argument('--upscale_factor', type=int, default=4, help=\"super resolution upscale factor\")\n",
    "parser.add_argument('--testBatchSize', type=int, default=1, help='testing batch size')\n",
    "parser.add_argument('--batch_size', type=int, default=2, help='training batch size') # GPU: 9GB!\n",
    "parser.add_argument('--threads', type=int, default=2, help='number of threads for data loading')\n",
    "parser.add_argument('--seed', type=int, default=123, help='random seed to use. Default=123')\n",
    "parser.add_argument('--gpu_mode', type=bool, default=True)\n",
    "parser.add_argument('--gpus', default=1, type=float, help='number of gpu')\n",
    "#parser.add_argument('--test_dataset', type=str, default='VOC12-LR-X8-test')\n",
    "#parser.add_argument('--sr_dataset', type=str, default='VOC12-SR-X8')\n",
    "parser.add_argument('--train_dataset', type=str, default='VOC12-LR-x4')\n",
    "parser.add_argument('--hr_dataset', type=str, default='VOC12-HR')\n",
    "parser.add_argument('--anno_path', type=str, default='Annotations')\n",
    "parser.add_argument('--imSetpath', type=str, default='ImageSets')\n",
    "parser.add_argument('--input_dir', type=str, default='./dataset')\n",
    "#parser.add_argument('--output', default='./dataset/results', help='Location to save some outputs')\n",
    "parser.add_argument('--checkpt', default='./checkpoint', help='Location to save checkpoint models')\n",
    "parser.add_argument('--lr', type=float, default=1e-4, help='Learning Rate. Default=0.0001')\n",
    "parser.add_argument('--nEpochs', type=int, default=5, help='number of epochs to fine tune net S over target loss')\n",
    "\n",
    "opt = parser.parse_args()\n",
    "\n",
    "gpus_list=range(opt.gpus)\n",
    "print(opt)\n",
    "\n",
    "cuda = opt.gpu_mode\n",
    "if cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run without --cuda\")\n",
    "\n",
    "torch.manual_seed(opt.seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(opt.seed)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "num_classes = 21           # 20 (VOC0712) +1 for background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading SSD300 task evaluation network!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x/cs231n/super-resolution-detection/ssd/ssd.py:34: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.priors = Variable(self.priorbox.forward(), volatile=True)\n",
      "/home/x/cs231n/super-resolution-detection/ssd/layers/modules/l2norm.py:17: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.weight,self.gamma)\n"
     ]
    }
   ],
   "source": [
    "# Task validation Setup - We use VOC07 Detection validation for our SROD network\n",
    "\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "voc_root = os.path.join(HOME, \"data/VOCdevkit/\")\n",
    "\n",
    "annopath = os.path.join(voc_root, 'VOC2007', 'Annotations', '%s.xml')\n",
    "imgpath = os.path.join(voc_root, 'VOC2007', 'JPEGImages', '%s.jpg')\n",
    "imgsetpath = os.path.join(voc_root, 'VOC2007', 'ImageSets', 'Main', '{:s}.txt')\n",
    "YEAR = '2007'\n",
    "devkit_path = voc_root + 'VOC' + YEAR\n",
    "# VOC0712 image channel MEANS\n",
    "dataset_mean = (104, 117, 123)\n",
    "\n",
    "# Random picked detection network end-task validation set,\n",
    "# N.B. it is not for SROD (DBPN+SSD) training target Loss.\n",
    "set_type = '07val32-5702'\n",
    "# set_typs is explained below:\n",
    "\"\"\"\n",
    "We have 5 validation sets to choose, size of 16, 32, 64, 128, 256 repectively,\n",
    "Due to the time & computation constraint, we have these 5 downsampled val set.\n",
    "They are randomly(no replacement) picked from  VOC2007/ImageSets/Main/val.txt.\n",
    "\n",
    "Baseline mAP on Pre-trained ssd300 is measured as well:       (mAP)\n",
    "These Detection baseline are measured on frozen SSD300 network using\n",
    "'weights/ssd300_mAP_77.43_v2.pth', for 75x75 LR images been SR-ed by\n",
    "VOC12 retrained DBPN baseline w. weight 'VOC12-LR-x4-DBPN-ep100.pth'.\n",
    "\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val16-5648.txt      56.48%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val32-5702.txt      57.02%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val64-5826.txt      58.26%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val128-6019.txt     60.19%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val256-6030.txt     60.30%\n",
    "\n",
    "These can be used to evaluate training in progress quantatively.\n",
    "Again we do not run through whole val set for periodical check out, too slow!\n",
    "\"\"\"\n",
    "\n",
    "# Utility functions\n",
    "def save_img(img, img_path):\n",
    "    save_img = img.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n",
    "    cv2.imwrite(img_path, cv2.cvtColor(save_img*255, cv2.COLOR_BGR2RGB),  [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "# Dataloader for SuperVision Subnetwork Evaluation\n",
    "eval_set = DBPNLoader(root='./dataset')\n",
    "eval_loader = DataLoader(dataset=eval_set, batch_size=1, num_workers=1, shuffle=False)\n",
    "\n",
    "\n",
    "# Network and Dataloader for Detection subnetwork to End Task Eval\n",
    "# Tried to reuse 2nd half of our SRD net for detection, not lucky!\n",
    "ssd300net = build_ssd('test', 300, num_classes)   # initialize SSD\n",
    "ssd300net.load_state_dict(torch.load('ssd/weights/ssd300_mAP_77.43_v2.pth'))\n",
    "ssd300net.eval()\n",
    "\n",
    "print('Finished loading SSD300 task evaluation network!')\n",
    "eval_det = VOCDetection(voc_root, [('2007', set_type)],\n",
    "                       BaseTransform(300, dataset_mean),\n",
    "                       VOCAnnotationTransform(), sr_path='./dataset/VOC07-SR-x4')\n",
    "if cuda:\n",
    "     ssd300net = ssd300net.cuda()\n",
    "     cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading SRD sub Net-S (DBPN) fine-tune training datasets (VOC12)\n"
     ]
    }
   ],
   "source": [
    "print('===> Loading SRD sub Net-S (DBPN) fine-tune training datasets (VOC12)')\n",
    "\n",
    "sd_dataset = SRDetection(root='./dataset', image_sets='trainval.txt', data_mean = dataset_mean,\n",
    "                         target_transform = VOCAnnotationTransform())\n",
    "\n",
    "sd_data_loader = DataLoader(dataset=sd_dataset, batch_size=opt.batch_size, num_workers=opt.threads,\n",
    "                            shuffle=False, collate_fn=detection_collate, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Architecture Definition of SRD network model: Net-S (DBPN) + Net-D (SSD300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x/cs231n/super-resolution-detection/dbpn/dbpn.py:47: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  torch.nn.init.kaiming_normal(m.weight)\n",
      "/home/x/cs231n/super-resolution-detection/dbpn/dbpn.py:51: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  torch.nn.init.kaiming_normal(m.weight)\n",
      "/home/x/cs231n/super-resolution-detection/ssd/ssd.py:34: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.priors = Variable(self.priorbox.forward(), volatile=True)\n",
      "/home/x/cs231n/super-resolution-detection/ssd/layers/modules/l2norm.py:17: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.weight,self.gamma)\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "# 1. come up with test/eval functions\n",
    "# 2. come up with visualization image\n",
    "\n",
    "print('===> Architecture Definition of SRD network model: Net-S (DBPN) + Net-D (SSD300)')\n",
    "\n",
    "\n",
    "class DBPN2SSD(nn.Module):\n",
    "    \n",
    "    def __init__(self, s_model_name, d_model_name, d_frozen):\n",
    "        super(DBPN2SSD, self).__init__()\n",
    "        self.supervis = DBPN(num_channels=3, base_filter=64, feat=256, num_stages=7, scale_factor=4)\n",
    "        if os.path.exists(s_model_name):\n",
    "            self.supervis = torch.nn.DataParallel(self.supervis, device_ids=gpus_list)\n",
    "            self.supervis.load_state_dict(torch.load(s_model_name, map_location=lambda storage, loc: storage))\n",
    "\n",
    "        # self.detector = SSD(), setup ssd as 'train' mode for gradient flow\n",
    "        # later at test/eval situation, we will overwrite it's mode to 'test'\n",
    "        self.detector = build_ssd('train', 300, num_classes)\n",
    "        if os.path.exists(d_model_name):\n",
    "            self.detector.load_state_dict(torch.load(d_model_name, map_location=lambda storage, loc: storage))\n",
    "        if d_frozen:\n",
    "            for param in self.detector.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        superx = self.supervis(x)\n",
    "        # current detector: SSD300, so assume superx: 300x300!\n",
    "        detect = self.detector(superx)\n",
    "        return (superx, detect)\n",
    "\n",
    "\n",
    "#SDnet = DBPN2SSD('dbpn/models/DBPN_x4.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "#SDnet = DBPN2SSD('checkpoint/SRx4_4000.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "SRDnet = DBPN2SSD('dbpn/models/VOC12-LR-x4-DBPN-ep100.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections\n",
      "0.32516572842066116\n"
     ]
    }
   ],
   "source": [
    "def mAP_eval():\n",
    "    mAP = test_net('./eval', ssd300net, cuda, eval_det, BaseTransform(ssd300net.size, dataset_mean), \\\n",
    "                   5, 300, thresh=0.01, eval_set=set_type)\n",
    "    return mAP\n",
    "    \n",
    "print(mAP_eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main SRD training Loop\n",
    "\n",
    "# Hyperparameters - balancing weights of net S loss vs. net D loss\n",
    "alpha = 1.0\n",
    "beta = 1.0\n",
    "\n",
    "decay_steps = [5000, 10000, 20000, 40000, 80000, 160000]\n",
    "gamma = 0.1\n",
    "def adjust_learning_rate(optimizer, gamma=0.1, step=0):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every\n",
    "        specified step\n",
    "    # Adapted from PyTorch Imagenet example:\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    lr = opt.lr * (gamma ** (step))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "# discover 'best' dbpn model according to an eval set\n",
    "best_dbpn_model = None\n",
    "best_val = -1\n",
    "prev_file = None\n",
    "\n",
    "def train(SDnet):\n",
    "    best_val = -1\n",
    "    prev_file = None\n",
    "    \n",
    "  \n",
    "    net = SDnet\n",
    "\n",
    "    # Criterions:\n",
    "    #\n",
    "    # net SR loss function, change to L2 later\n",
    "    criterion_sr = nn.MSELoss()\n",
    "\n",
    "    # ssd loss function\n",
    "    criterion_ssd = MultiBoxLoss(voc['num_classes'], 0.5, True, 0, True, 3, 0.5, False, use_gpu=cuda)\n",
    "\n",
    "    if cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        #net.supervis = torch.nn.DataParallel(net.supervis)\n",
    "        cudnn.benchmark = True\n",
    "        net = net.cuda(gpus_list[0])\n",
    "        criterion_sr = criterion_sr.cuda(gpus_list[0])\n",
    "        criterion_ssd = criterion_ssd.cuda(gpus_list[0])\n",
    "\n",
    "\n",
    "    # optimizer = optim.SGD(net.supervis.parameters(), lr=opt.lr, \\\n",
    "    #                       momentum=opt.momentum, weight_decay=opt.weight_decay)\n",
    "    #\n",
    "    # Use universal Adam first :)\n",
    "    # we can be Specific to what part of network's parameters to optimize, here is SuperR Net\n",
    "    optimizer = optim.Adam(net.supervis.parameters(), lr=opt.lr, betas=(0.9, 0.999), eps=1e-8)\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # set model to training mode\n",
    "    net.train()\n",
    "    \n",
    "    epoch = 1\n",
    "    #max_iter = 20000\n",
    "    max_iter = 1000\n",
    "    decay_step = 0\n",
    "    for iteration, batch in enumerate(sd_data_loader, 1):\n",
    "        \n",
    "        if iteration == max_iter:\n",
    "            break\n",
    "        if iteration in decay_steps:\n",
    "            decay_step += 1\n",
    "            adjust_learning_rate(optimizer, gamma, decay_step)\n",
    "            \n",
    "        # input is LR image; sr_target is pseudo (300x300) original HR image, det_target is bboxes\n",
    "        input, sr_target, det_target = batch[0], batch[1], batch[2]\n",
    "        if cuda:\n",
    "            input = Variable(input.cuda(gpus_list[0]))\n",
    "            sr_target = Variable(sr_target.cuda(gpus_list[0]))\n",
    "            det_target = [Variable(ann.cuda(gpus_list[0]), volatile=True) for ann in det_target]\n",
    "        else:\n",
    "            input = Variable(input)\n",
    "            sr_target = Variable(sr_target)\n",
    "            det_target = [Variable(ann, volatile=True) for ann in det_target]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        t0 = time()\n",
    "        \n",
    "        sr_out,ssd_out = net(input)\n",
    "        loss_sr = criterion_sr(sr_out, sr_target)\n",
    "        \n",
    "        # Compound Loss from net-S: loss_sr and net-D: loss_l, loss_c\n",
    "        loss_l, loss_c = criterion_ssd(ssd_out, det_target)\n",
    "        loss = loss_sr * alpha + beta *(loss_l + loss_c)\n",
    "        \n",
    "        epoch_loss += loss.data[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t1 = time()\n",
    "\n",
    "        if iteration != 0 and iteration % 20 == 0:\n",
    "            print(\"===> Epoch[{}]({}/{}): Loss: {:.4f} || Timer: {:.4f} sec.\".format(epoch, \\\n",
    "                        iteration, len(sd_data_loader), loss.data[0], (t1 - t0)))\n",
    "\n",
    "        # End Task (detection) & Imaging Quality Evaluation vs. Model Loss steps below:\n",
    "        if iteration != 0 and iteration % 200 == 0:\n",
    "            net.eval()\n",
    "            #num_images = len(eval_set)\n",
    "            #for i in range(num_images):\n",
    "            i, ssim, psnr  = 0, 0, 0\n",
    "            for iter, bat in enumerate(eval_loader, 1):\n",
    "                # loader output:  lr,     hr,   fname\n",
    "                lr, hr, fname = bat[0], bat[1], bat[2]\n",
    "                # lr, hr, fname = eval_set.pull_item(i)\n",
    "                if cuda:\n",
    "                    lr_v = Variable(lr.cuda(gpus_list[0]))\n",
    "                else:\n",
    "                    lr_v = Variable(lr)\n",
    "                sr, _ = net(lr_v)\n",
    "                srimg = sr.cpu().data\n",
    "                hrimg = hr.data\n",
    "                \n",
    "                # Struct Similarity Index & Peak Signal-Noise Ratio\n",
    "                ssim += metric_ssim(hrimg.numpy(), srimg.numpy())\n",
    "                psnr += metric_psnr(hrimg.numpy(), srimg.numpy())\n",
    "                i += 1\n",
    "                #print(\"ssim, psnr:\", ssim, psnr)\n",
    "                \n",
    "                image=srimg\n",
    "                image = (image - image.min())/(image.max() - image.min())\n",
    "                imagef = os.path.join('./dataset/VOC07-SR-x4/', '%s.jpg')\n",
    "                save_img(image, imagef % fname)\n",
    "                \n",
    "            mSSIM = ssim / i\n",
    "            mPSNR = psnr / i\n",
    "            mAP_acc = mAP_eval()\n",
    "            print(\"Mean AP = {:.4f}, Mean SSIM = {:.4f}, Mean PSNR = {:.4f}\".format(mAP_acc, mSSIM, mPSNR))\n",
    "            mAP_int = int(mAP_acc * 10000)\n",
    "            if mAP_int > best_val:\n",
    "                best_val = mAP_int\n",
    "                if prev_file is not None:\n",
    "                    os.remove(prev_file)\n",
    "                chkfile = opt.checkpt + '/' + 'SRx4_' + repr(iteration+4000) + '_mAP' + repr(best_val) + '.pth'\n",
    "                torch.save(net.supervis.state_dict(), chkfile)\n",
    "                prev_file = chkfile\n",
    "                \n",
    "            # back to training mode\n",
    "            net.train()\n",
    "        \n",
    "        if iteration != 0 and iteration % 2000 == 0:\n",
    "            print('Saving state, iter:', iteration)\n",
    "            torch.save(net.supervis.state_dict(), opt.checkpt + '/' + 'SRx4_' + repr(iteration+4000) + '.pth')\n",
    "\n",
    "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(sd_data_loader)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__:76: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "__main__:92: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "__main__:98: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[1](20/5770): Loss: 5141.9956 || Timer: 0.3346 sec.\n",
      "===> Epoch[1](40/5770): Loss: 1852.7997 || Timer: 0.3331 sec.\n",
      "===> Epoch[1](60/5770): Loss: 1699.5229 || Timer: 0.3424 sec.\n",
      "===> Epoch[1](80/5770): Loss: 1531.7385 || Timer: 0.3361 sec.\n",
      "===> Epoch[1](100/5770): Loss: 1405.6626 || Timer: 0.3395 sec.\n",
      "===> Epoch[1](120/5770): Loss: 851.3445 || Timer: 0.3337 sec.\n",
      "===> Epoch[1](140/5770): Loss: 1517.8903 || Timer: 0.3373 sec.\n",
      "===> Epoch[1](160/5770): Loss: 1262.6099 || Timer: 0.3775 sec.\n",
      "===> Epoch[1](180/5770): Loss: 1424.9941 || Timer: 0.3357 sec.\n",
      "===> Epoch[1](200/5770): Loss: 548.8506 || Timer: 0.3456 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x/cs231n/super-resolution-detection/metric.py:188: RuntimeWarning: invalid value encountered in power\n",
      "  return (np.prod(mcs[0:levels - 1]**weights[0:levels - 1]) *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections\n",
      "Mean AP = -0.0033, Mean SSIM = nan, Mean PSNR = 19.1272\n",
      "===> Epoch[1](220/5770): Loss: 759.6493 || Timer: 0.3352 sec.\n",
      "===> Epoch[1](240/5770): Loss: 1061.2609 || Timer: 0.3430 sec.\n",
      "===> Epoch[1](260/5770): Loss: 952.2111 || Timer: 0.3360 sec.\n",
      "===> Epoch[1](280/5770): Loss: 461.9155 || Timer: 0.3362 sec.\n",
      "===> Epoch[1](300/5770): Loss: 784.3394 || Timer: 0.3466 sec.\n",
      "===> Epoch[1](320/5770): Loss: 693.6909 || Timer: 0.3403 sec.\n",
      "===> Epoch[1](340/5770): Loss: 698.8302 || Timer: 0.3559 sec.\n",
      "===> Epoch[1](360/5770): Loss: 816.1056 || Timer: 0.3467 sec.\n",
      "===> Epoch[1](380/5770): Loss: 733.9493 || Timer: 0.3474 sec.\n",
      "===> Epoch[1](400/5770): Loss: 781.3439 || Timer: 0.3632 sec.\n",
      "Evaluating detections\n",
      "Mean AP = 0.2689, Mean SSIM = 0.8776, Mean PSNR = 20.7416\n",
      "===> Epoch[1](420/5770): Loss: 396.0281 || Timer: 0.3358 sec.\n",
      "===> Epoch[1](440/5770): Loss: 962.0947 || Timer: 0.3435 sec.\n",
      "===> Epoch[1](460/5770): Loss: 333.1998 || Timer: 0.3348 sec.\n",
      "===> Epoch[1](480/5770): Loss: 221.5724 || Timer: 0.3455 sec.\n",
      "===> Epoch[1](500/5770): Loss: 799.3977 || Timer: 0.3374 sec.\n",
      "===> Epoch[1](520/5770): Loss: 467.7590 || Timer: 0.3403 sec.\n",
      "===> Epoch[1](540/5770): Loss: 563.9302 || Timer: 0.3503 sec.\n",
      "===> Epoch[1](560/5770): Loss: 402.8945 || Timer: 0.3341 sec.\n",
      "===> Epoch[1](580/5770): Loss: 604.0751 || Timer: 0.3436 sec.\n",
      "===> Epoch[1](600/5770): Loss: 143.3347 || Timer: 0.3410 sec.\n",
      "Evaluating detections\n",
      "Mean AP = 0.4167, Mean SSIM = 0.9054, Mean PSNR = 22.1755\n",
      "===> Epoch[1](620/5770): Loss: 408.8576 || Timer: 0.3360 sec.\n",
      "===> Epoch[1](640/5770): Loss: 359.5764 || Timer: 0.3456 sec.\n",
      "===> Epoch[1](660/5770): Loss: 241.5436 || Timer: 0.3578 sec.\n",
      "===> Epoch[1](680/5770): Loss: 419.1935 || Timer: 0.3391 sec.\n",
      "===> Epoch[1](700/5770): Loss: 539.0698 || Timer: 0.3398 sec.\n",
      "===> Epoch[1](720/5770): Loss: 259.8925 || Timer: 0.3433 sec.\n",
      "===> Epoch[1](740/5770): Loss: 651.0859 || Timer: 0.3384 sec.\n",
      "===> Epoch[1](760/5770): Loss: 471.9618 || Timer: 0.3385 sec.\n",
      "===> Epoch[1](780/5770): Loss: 765.1210 || Timer: 0.3495 sec.\n",
      "===> Epoch[1](800/5770): Loss: 422.7682 || Timer: 0.3400 sec.\n",
      "Evaluating detections\n",
      "Mean AP = 0.4305, Mean SSIM = 0.8886, Mean PSNR = 22.0037\n",
      "===> Epoch[1](820/5770): Loss: 542.5662 || Timer: 0.3418 sec.\n"
     ]
    }
   ],
   "source": [
    "train(SRDnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging code below, no need to run :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' YOU Donot need to run this ===> Loading some datasets')\n",
    "\n",
    "lr_path = os.path.join(opt.input_dir, opt.train_dataset)\n",
    "hr_path = os.path.join(opt.input_dir, opt.hr_dataset)\n",
    "\n",
    "fine_train_set = get_pair_set(lr_path, hr_path)\n",
    "train_data_loader = DataLoader(dataset=fine_train_set, num_workers=opt.threads, \\\n",
    "                               batch_size=opt.testBatchSize, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_test():\n",
    "    SDnet = DBPN2SSD('dbpn/models/DBPN_x4.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "    net = SDnet\n",
    "    \n",
    "    if cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = True\n",
    "        net = net.cuda()\n",
    "\n",
    "    else:\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "\n",
    "    \n",
    "simple_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor ## UNCOMMENT THIS LINE IF YOU'RE ON A GPU!\n",
    "\n",
    "# Real samples were all associated with Ture labels - 1\n",
    "T_labels = torch.ones(logits_real.size()).type(dtype)\n",
    "# Fake samples were all associated with Fake labels - 0\n",
    "F_labels = torch.zeros(logits_fake.size()).type(dtype)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
