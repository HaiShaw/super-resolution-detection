{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The following code is modified based on the original torchcv project. \n",
    "* We are going to use PASACAL VOC12 as dataset.\n",
    "* You could donwload VOC2012 \n",
    "  train/validation: http://host.robots.ox.ac.uk/pascal/VOC/voc2012/#devkit\n",
    "* test data: https://pjreddie.com/projects/pascal-voc-dataset-mirror/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from __future__ import print_function\n",
    "from dbpn import Net as DBPN\n",
    "from dbpn import get_pair_set\n",
    "from ssd import SSD\n",
    "from ssd import build_ssd\n",
    "from ssd.layers.modules import MultiBoxLoss\n",
    "from ssd.data.config import voc\n",
    "from ssd.data import detection_collate\n",
    "from ssd.data import VOCAnnotationTransform, VOCDetection, BaseTransform, SRDetection, DBPNLoader\n",
    "from ssd.eval import test_net\n",
    "from metric import *\n",
    "\n",
    "import sys; sys.argv=['']; del sys\n",
    "\n",
    "# clean up device\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(anno_path='Annotations', batch_size=2, checkpt='./checkpoint', gpu_mode=True, gpus=1, hr_dataset='VOC12-HR', imSetpath='ImageSets', input_dir='./dataset', lr=0.0001, nEpochs=10, seed=123, testBatchSize=1, threads=2, train_dataset='VOC12-LR-x4', upscale_factor=4)\n"
     ]
    }
   ],
   "source": [
    "# Global arguments & settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch Super Resolution Detection Networks')\n",
    "parser.add_argument('--upscale_factor', type=int, default=4, help=\"super resolution upscale factor\")\n",
    "parser.add_argument('--testBatchSize', type=int, default=1, help='testing batch size')\n",
    "parser.add_argument('--batch_size', type=int, default=2, help='training batch size') # GPU: 9GB!\n",
    "parser.add_argument('--threads', type=int, default=2, help='number of threads for data loading')\n",
    "parser.add_argument('--seed', type=int, default=123, help='random seed to use. Default=123')\n",
    "parser.add_argument('--gpu_mode', type=bool, default=True)\n",
    "parser.add_argument('--gpus', default=1, type=float, help='number of gpu')\n",
    "#parser.add_argument('--test_dataset', type=str, default='VOC12-LR-X8-test')\n",
    "#parser.add_argument('--sr_dataset', type=str, default='VOC12-SR-X8')\n",
    "parser.add_argument('--train_dataset', type=str, default='VOC12-LR-x4')\n",
    "parser.add_argument('--hr_dataset', type=str, default='VOC12-HR')\n",
    "parser.add_argument('--anno_path', type=str, default='Annotations')\n",
    "parser.add_argument('--imSetpath', type=str, default='ImageSets')\n",
    "parser.add_argument('--input_dir', type=str, default='./dataset')\n",
    "#parser.add_argument('--output', default='./dataset/results', help='Location to save some outputs')\n",
    "parser.add_argument('--checkpt', default='./checkpoint', help='Location to save checkpoint models')\n",
    "parser.add_argument('--lr', type=float, default=1e-4, help='Learning Rate. Default=0.0001')\n",
    "parser.add_argument('--nEpochs', type=int, default=10, help='number of epochs to fine tune net S over target loss')\n",
    "\n",
    "opt = parser.parse_args()\n",
    "\n",
    "gpus_list=range(opt.gpus)\n",
    "print(opt)\n",
    "\n",
    "cuda = opt.gpu_mode\n",
    "if cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run without --cuda\")\n",
    "\n",
    "torch.manual_seed(opt.seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(opt.seed)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "Epochs = opt.nEpochs\n",
    "tbz = opt.batch_size\n",
    "num_classes = 21           # 20 (VOC0712) +1 for background\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x/cs231n/super-resolution-detection/ssd/ssd.py:34: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.priors = Variable(self.priorbox.forward(), volatile=True)\n",
      "/home/x/cs231n/super-resolution-detection/ssd/layers/modules/l2norm.py:17: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.weight,self.gamma)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading SSD300 task evaluation network!\n"
     ]
    }
   ],
   "source": [
    "# Task validation Setup - We use VOC07 Detection validation for our SROD network\n",
    "\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "voc_root = os.path.join(HOME, \"data/VOCdevkit/\")\n",
    "\n",
    "annopath = os.path.join(voc_root, 'VOC2007', 'Annotations', '%s.xml')\n",
    "imgpath = os.path.join(voc_root, 'VOC2007', 'JPEGImages', '%s.jpg')\n",
    "imgsetpath = os.path.join(voc_root, 'VOC2007', 'ImageSets', 'Main', '{:s}.txt')\n",
    "YEAR = '2007'\n",
    "devkit_path = voc_root + 'VOC' + YEAR\n",
    "# VOC0712 image channel MEANS\n",
    "dataset_mean = (104, 117, 123)\n",
    "\n",
    "# Random picked detection network end-task validation set,\n",
    "# N.B. it is not for SROD (DBPN+SSD) training target Loss.\n",
    "set_type = '07val32-5702'\n",
    "# set_typs is explained below:\n",
    "\"\"\"\n",
    "We have 5 validation sets to choose, size of 16, 32, 64, 128, 256 repectively,\n",
    "Due to the time & computation constraint, we have these 5 downsampled val set.\n",
    "They are randomly(no replacement) picked from  VOC2007/ImageSets/Main/val.txt.\n",
    "\n",
    "Baseline mAP on Pre-trained ssd300 is measured as well:       (mAP)\n",
    "These Detection baseline are measured on frozen SSD300 network using\n",
    "'weights/ssd300_mAP_77.43_v2.pth', for 75x75 LR images been SR-ed by\n",
    "VOC12 retrained DBPN baseline w. weight 'VOC12-LR-x4-DBPN-ep100.pth'.\n",
    "\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val16-5648.txt      56.48%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val32-5702.txt      57.02%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val64-5826.txt      58.26%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val128-6019.txt     60.19%\n",
    "~/data/VOCdevkit/VOC2007/ImageSets/Main/07val256-6030.txt     60.30%\n",
    "\n",
    "These can be used to evaluate training in progress quantatively.\n",
    "Again we do not run through whole val set for periodical check out, too slow!\n",
    "\"\"\"\n",
    "\n",
    "# Utility functions\n",
    "def save_img(img, img_path):\n",
    "    save_img = img.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n",
    "    cv2.imwrite(img_path, cv2.cvtColor(save_img*255, cv2.COLOR_BGR2RGB),  [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "# Dataloader for SuperVision Subnetwork Evaluation\n",
    "eval_set = DBPNLoader(root='./dataset')\n",
    "eval_loader = DataLoader(dataset=eval_set, batch_size=1, num_workers=1, shuffle=False)\n",
    "\n",
    "\n",
    "# Network and Dataloader for Detection subnetwork to End Task Eval\n",
    "# Tried to reuse 2nd half of our SRD net for detection, not lucky!\n",
    "ssd300net = build_ssd('test', 300, num_classes)   # initialize SSD\n",
    "ssd300net.load_state_dict(torch.load('ssd/weights/ssd300_mAP_77.43_v2.pth'))\n",
    "ssd300net.eval()\n",
    "\n",
    "print('Finished loading SSD300 task evaluation network!')\n",
    "eval_det = VOCDetection(voc_root, [('2007', set_type)],\n",
    "                       BaseTransform(300, dataset_mean),\n",
    "                       VOCAnnotationTransform(), sr_path='./dataset/VOC07-SR-x4')\n",
    "if cuda:\n",
    "     ssd300net = ssd300net.cuda()\n",
    "     cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading SRD sub Net-S (DBPN) fine-tune training datasets (VOC12)\n"
     ]
    }
   ],
   "source": [
    "print('===> Loading SRD sub Net-S (DBPN) fine-tune training datasets (VOC12)')\n",
    "\n",
    "sd_dataset = SRDetection(root='./dataset', image_sets='trainval.txt', data_mean = dataset_mean,\n",
    "                         target_transform = VOCAnnotationTransform())\n",
    "\n",
    "sd_data_loader = DataLoader(dataset=sd_dataset, batch_size=opt.batch_size, num_workers=opt.threads,\n",
    "                            shuffle=False, collate_fn=detection_collate, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Architecture Definition of SRD network model: Net-S (DBPN) + Net-D (SSD300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x/cs231n/super-resolution-detection/dbpn/dbpn.py:47: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  torch.nn.init.kaiming_normal(m.weight)\n",
      "/home/x/cs231n/super-resolution-detection/dbpn/dbpn.py:51: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  torch.nn.init.kaiming_normal(m.weight)\n",
      "/home/x/cs231n/super-resolution-detection/ssd/ssd.py:34: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.priors = Variable(self.priorbox.forward(), volatile=True)\n",
      "/home/x/cs231n/super-resolution-detection/ssd/layers/modules/l2norm.py:17: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.weight,self.gamma)\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "# 1. come up with test/eval functions\n",
    "# 2. come up with visualization image\n",
    "\n",
    "print('===> Architecture Definition of SRD network model: Net-S (DBPN) + Net-D (SSD300)')\n",
    "\n",
    "\n",
    "class DBPN2SSD(nn.Module):\n",
    "    \n",
    "    def __init__(self, s_model_name, d_model_name, d_frozen):\n",
    "        super(DBPN2SSD, self).__init__()\n",
    "        self.supervis = DBPN(num_channels=3, base_filter=64, feat=256, num_stages=7, scale_factor=4)\n",
    "        if os.path.exists(s_model_name):\n",
    "            self.supervis = torch.nn.DataParallel(self.supervis, device_ids=gpus_list)\n",
    "            self.supervis.load_state_dict(torch.load(s_model_name, map_location=lambda storage, loc: storage))\n",
    "\n",
    "        # self.detector = SSD(), setup ssd as 'train' mode for gradient flow\n",
    "        # later at test/eval situation, we will overwrite it's mode to 'test'\n",
    "        self.detector = build_ssd('train', 300, num_classes)\n",
    "        if os.path.exists(d_model_name):\n",
    "            self.detector.load_state_dict(torch.load(d_model_name, map_location=lambda storage, loc: storage))\n",
    "        if d_frozen:\n",
    "            for param in self.detector.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        superx = self.supervis(x)\n",
    "        # current detector: SSD300, so assume superx: 300x300!\n",
    "        detect = self.detector(superx)\n",
    "        return (superx, detect)\n",
    "\n",
    "\n",
    "#SDnet = DBPN2SSD('dbpn/models/DBPN_x4.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "#SDnet = DBPN2SSD('checkpoint/SRx4_4000.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "SRDnet = DBPN2SSD('dbpn/models/VOC12-LR-x4-DBPN-ep100.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections\n",
      "0.5931584438968626\n"
     ]
    }
   ],
   "source": [
    "def mAP_eval():\n",
    "    mAP = test_net('./eval', ssd300net, cuda, eval_det, BaseTransform(ssd300net.size, dataset_mean), \\\n",
    "                   5, 300, thresh=0.01, eval_set=set_type)\n",
    "    return mAP\n",
    "    \n",
    "print(mAP_eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main SRD training Loop\n",
    "\n",
    "# Hyperparameters - balancing weights of net S loss vs. net D loss\n",
    "alpha = 1.0\n",
    "beta = 1.0\n",
    "\n",
    "Epochs = 2\n",
    "# decay_steps = [5000, 10000, 20000, 40000, 80000] in iterations\n",
    "# decay_steps = [5, 10, 20, 40, 80]              # in epochs\n",
    "# decay_steps = [4, 8]                           # in epochs\n",
    "# experimental: half LR at 3rd epoch\n",
    "decay_steps = [3]                                # in epochs\n",
    "gamma = 0.1\n",
    "def adjust_learning_rate(optimizer, gamma=0.1, step=0):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every\n",
    "        specified step\n",
    "    # Adapted from PyTorch Imagenet example:\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    gamma = 0.5\n",
    "    lr = opt.lr * (gamma ** (step))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "# discover 'best' dbpn model according to an eval set\n",
    "best_dbpn_model = None\n",
    "best_val = -1\n",
    "prev_file = None\n",
    "\n",
    "def train(SDnet):\n",
    "    best_val = -1\n",
    "    prev_file = None\n",
    "    \n",
    "  \n",
    "    net = SDnet\n",
    "\n",
    "    # Criterions:\n",
    "    #\n",
    "    # net SR loss function, change to L2 later\n",
    "    criterion_sr = nn.MSELoss()\n",
    "\n",
    "    # ssd loss function\n",
    "    criterion_ssd = MultiBoxLoss(voc['num_classes'], 0.5, True, 0, True, 3, 0.5, False, use_gpu=cuda)\n",
    "\n",
    "    if cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        #net.supervis = torch.nn.DataParallel(net.supervis)\n",
    "        cudnn.benchmark = True\n",
    "        net = net.cuda(gpus_list[0])\n",
    "        criterion_sr = criterion_sr.cuda(gpus_list[0])\n",
    "        criterion_ssd = criterion_ssd.cuda(gpus_list[0])\n",
    "\n",
    "\n",
    "    # optimizer = optim.SGD(net.supervis.parameters(), lr=opt.lr, \\\n",
    "    #                       momentum=opt.momentum, weight_decay=opt.weight_decay)\n",
    "    #\n",
    "    # Use universal Adam first :)\n",
    "    # we can be Specific to what part of network's parameters to optimize, here is SuperR Net\n",
    "    optimizer = optim.Adam(net.supervis.parameters(), lr=opt.lr, betas=(0.9, 0.999), eps=1e-8)\n",
    "    \n",
    "    # set model to training mode\n",
    "    net.train()\n",
    "    \n",
    "    #epoch = 1\n",
    "    #max_iter = 20000\n",
    "    max_iter  =  5600    # Approx. within 1 Epoch 5600/5770\n",
    "    decay_step = 0\n",
    "    for epoch in range(1, Epochs + 1):\n",
    "        t_0 = time()\n",
    "        epoch_loss = 0\n",
    "        iters_loss = 0\n",
    "        for iteration, batch in enumerate(sd_data_loader, 1):\n",
    "\n",
    "            if iteration == max_iter + 1:\n",
    "                break\n",
    "            if epoch in decay_steps:\n",
    "                decay_step += 1\n",
    "                adjust_learning_rate(optimizer, gamma, decay_step)\n",
    "\n",
    "            # input is LR image; sr_target is pseudo (300x300) original HR image, det_target is bboxes\n",
    "            input, sr_target, det_target = batch[0], batch[1], batch[2]\n",
    "            if cuda:\n",
    "                input = Variable(input.cuda(gpus_list[0]))\n",
    "                sr_target = Variable(sr_target.cuda(gpus_list[0]))\n",
    "                det_target = [Variable(ann.cuda(gpus_list[0]), volatile=True) for ann in det_target]\n",
    "            else:\n",
    "                input = Variable(input)\n",
    "                sr_target = Variable(sr_target)\n",
    "                det_target = [Variable(ann, volatile=True) for ann in det_target]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            t0 = time()\n",
    "\n",
    "            sr_out,ssd_out = net(input)\n",
    "            loss_sr = criterion_sr(sr_out, sr_target)\n",
    "\n",
    "            # Compound Loss from net-S: loss_sr and net-D: loss_l, loss_c\n",
    "            loss_l, loss_c = criterion_ssd(ssd_out, det_target)\n",
    "            loss = loss_sr * alpha + beta *(loss_l + loss_c)\n",
    "\n",
    "            epoch_loss += loss.data[0]\n",
    "            iters_loss += loss.data[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            t1 = time()\n",
    "\n",
    "            if iteration != 0 and iteration % 20 == 0:\n",
    "                print(\"===> Epoch[{}]({}/{}): Loss: {:.4f} || Time: {:.4f} sec.\".format(epoch, \\\n",
    "                            iteration, len(sd_data_loader), loss.data[0], (t1 - t0)))\n",
    "\n",
    "            # End Task (detection) & Imaging Quality Evaluation vs. Model Loss steps below:\n",
    "            if iteration != 0 and iteration % 200 == 0:\n",
    "                mItersLoss = iters_loss / 200\n",
    "                iters_loss = 0\n",
    "                net.eval()\n",
    "                t2 = time()\n",
    "                i, ssim, psnr  = 0, 0, 0\n",
    "                for iter, bat in enumerate(eval_loader, 1):\n",
    "                    # loader output:  lr,     hr,   fname\n",
    "                    lr, hr, fname = bat[0], bat[1], bat[2]\n",
    "                    # lr, hr, fname = eval_set.pull_item(i)\n",
    "                    if cuda:\n",
    "                        lr_v = Variable(lr.cuda(gpus_list[0]))\n",
    "                    else:\n",
    "                        lr_v = Variable(lr)\n",
    "                    sr, _ = net(lr_v)\n",
    "                    srimg = sr.cpu().data\n",
    "                    hrimg = hr.data\n",
    "\n",
    "                    # Struct Similarity Index & Peak Signal-Noise Ratio\n",
    "                    ssim += metric_ssim(hrimg.numpy(), srimg.numpy())\n",
    "                    psnr += metric_psnr(hrimg.numpy(), srimg.numpy())\n",
    "                    i += 1\n",
    "                    #print(\"ssim, psnr:\", ssim, psnr)\n",
    "\n",
    "                    image=srimg\n",
    "                    image = (image - image.min())/(image.max() - image.min())\n",
    "                    imagef = os.path.join('./dataset/VOC07-SR-x4/', '%s.jpg')\n",
    "                    save_img(image, imagef % fname)\n",
    "\n",
    "                mSSIM = ssim / i\n",
    "                mPSNR = psnr / i\n",
    "                mAP_acc = mAP_eval()\n",
    "                t3 = time()\n",
    "                print(\"Mean Loss = {:.4f}, Mean AP = {:.4f}, Mean SSIM = {:.4f}, Mean PSNR = {:.4f} || Time: {:.4f} sec.\"\\\n",
    "                      .format(mItersLoss, mAP_acc, mSSIM, mPSNR, (t3 - t2)))\n",
    "                mAP_int = int(mAP_acc * 10000)     #  2318 =>  23.18 %\n",
    "                mPSNR_i = int(mPSNR * 100)         #  2318 =>  23.18 dB\n",
    "                if math.isnan(mSSIM):\n",
    "                    mSSIM_i = 'NaN'\n",
    "                else:\n",
    "                    mSSIM_i = int(mSSIM * 10000)   #  2318 => 0.2318\n",
    "                if mAP_int > best_val:\n",
    "                    best_val = mAP_int\n",
    "                    if prev_file is not None:\n",
    "                        os.remove(prev_file)\n",
    "                    chkfile = opt.checkpt + '/' + 'SRx4_e' + repr(epoch) + '_i' + repr(iteration) + \\\n",
    "                              '_mAP' + repr(best_val) + '_mPSNR' + repr(mPSNR_i) + '_mSSIM' + repr(mSSIM_i) + '.pth'\n",
    "                    torch.save(net.supervis.state_dict(), chkfile)\n",
    "                    prev_file = chkfile\n",
    "\n",
    "                # back to training mode\n",
    "                net.train()\n",
    "\n",
    "            if iteration != 0 and iteration % 2000 == 0:\n",
    "                print('Saving state, iter:', iteration)\n",
    "                torch.save(net.supervis.state_dict(), opt.checkpt + '/' + 'SRx4_' + repr(iteration+4000) + '.pth')\n",
    "        t_1 = time()\n",
    "        print(\"===> Epoch {} Complete: Avg. Loss: {:.4f} || Time: {:.4f} sec.\"\\\n",
    "              .format(epoch, epoch_loss / (max_iter * tbz), (t_1 - t_0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__:85: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "__main__:101: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "__main__:102: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "__main__:108: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[1](20/5770): Loss: 5110.2388 || Time: 0.3231 sec.\n",
      "===> Epoch[1](40/5770): Loss: 2147.9971 || Time: 0.3246 sec.\n",
      "===> Epoch[1](60/5770): Loss: 1728.7394 || Time: 0.3249 sec.\n",
      "===> Epoch[1](80/5770): Loss: 1426.9573 || Time: 0.3248 sec.\n",
      "===> Epoch[1](100/5770): Loss: 1335.7742 || Time: 0.3319 sec.\n",
      "===> Epoch[1](120/5770): Loss: 787.1580 || Time: 0.3271 sec.\n",
      "===> Epoch[1](140/5770): Loss: 1487.0367 || Time: 0.3264 sec.\n",
      "===> Epoch[1](160/5770): Loss: 1240.0627 || Time: 0.3272 sec.\n",
      "===> Epoch[1](180/5770): Loss: 1434.2745 || Time: 0.3265 sec.\n",
      "===> Epoch[1](200/5770): Loss: 533.1248 || Time: 0.3247 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x/cs231n/super-resolution-detection/metric.py:188: RuntimeWarning: invalid value encountered in power\n",
      "  return (np.prod(mcs[0:levels - 1]**weights[0:levels - 1]) *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections\n",
      "Mean Loss = 3154.8877, Mean AP = 0.1127, Mean SSIM = nan, Mean PSNR = 19.2408 || Time: 10.2102 sec.\n",
      "===> Epoch[1](220/5770): Loss: 718.5680 || Time: 0.3274 sec.\n",
      "===> Epoch[1](240/5770): Loss: 1025.7302 || Time: 0.3268 sec.\n",
      "===> Epoch[1](260/5770): Loss: 905.5682 || Time: 0.3261 sec.\n",
      "===> Epoch[1](280/5770): Loss: 521.4319 || Time: 0.3356 sec.\n",
      "===> Epoch[1](300/5770): Loss: 643.6064 || Time: 0.3271 sec.\n",
      "===> Epoch[1](320/5770): Loss: 563.5612 || Time: 0.3363 sec.\n",
      "===> Epoch[1](340/5770): Loss: 560.6260 || Time: 0.3289 sec.\n",
      "===> Epoch[1](360/5770): Loss: 771.6061 || Time: 0.3277 sec.\n",
      "===> Epoch[1](380/5770): Loss: 692.7349 || Time: 0.3278 sec.\n",
      "===> Epoch[1](400/5770): Loss: 708.0773 || Time: 0.3283 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 765.6678, Mean AP = 0.2925, Mean SSIM = 0.8724, Mean PSNR = 21.1115 || Time: 9.4288 sec.\n",
      "===> Epoch[1](420/5770): Loss: 357.5675 || Time: 0.3286 sec.\n",
      "===> Epoch[1](440/5770): Loss: 903.1156 || Time: 0.3274 sec.\n",
      "===> Epoch[1](460/5770): Loss: 365.8387 || Time: 0.3316 sec.\n",
      "===> Epoch[1](480/5770): Loss: 213.5923 || Time: 0.3284 sec.\n",
      "===> Epoch[1](500/5770): Loss: 807.6990 || Time: 0.3273 sec.\n",
      "===> Epoch[1](520/5770): Loss: 449.2574 || Time: 0.3282 sec.\n",
      "===> Epoch[1](540/5770): Loss: 523.4650 || Time: 0.3294 sec.\n",
      "===> Epoch[1](560/5770): Loss: 387.3365 || Time: 0.3263 sec.\n",
      "===> Epoch[1](580/5770): Loss: 632.5222 || Time: 0.3306 sec.\n",
      "===> Epoch[1](600/5770): Loss: 217.0088 || Time: 0.3295 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 480.6255, Mean AP = 0.4273, Mean SSIM = 0.9079, Mean PSNR = 21.6110 || Time: 9.4387 sec.\n",
      "===> Epoch[1](620/5770): Loss: 444.4464 || Time: 0.3297 sec.\n",
      "===> Epoch[1](640/5770): Loss: 797.9949 || Time: 0.3295 sec.\n",
      "===> Epoch[1](660/5770): Loss: 264.0180 || Time: 0.3272 sec.\n",
      "===> Epoch[1](680/5770): Loss: 385.1027 || Time: 0.3370 sec.\n",
      "===> Epoch[1](700/5770): Loss: 488.8011 || Time: 0.3279 sec.\n",
      "===> Epoch[1](720/5770): Loss: 205.0667 || Time: 0.3272 sec.\n",
      "===> Epoch[1](740/5770): Loss: 631.1996 || Time: 0.3368 sec.\n",
      "===> Epoch[1](760/5770): Loss: 447.8373 || Time: 0.3284 sec.\n",
      "===> Epoch[1](780/5770): Loss: 687.3661 || Time: 0.3374 sec.\n",
      "===> Epoch[1](800/5770): Loss: 350.9091 || Time: 0.3435 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 471.2513, Mean AP = 0.4481, Mean SSIM = 0.9178, Mean PSNR = 22.5774 || Time: 9.5321 sec.\n",
      "===> Epoch[1](820/5770): Loss: 488.3362 || Time: 0.3283 sec.\n",
      "===> Epoch[1](840/5770): Loss: 507.6776 || Time: 0.3343 sec.\n",
      "===> Epoch[1](860/5770): Loss: 443.5318 || Time: 0.3295 sec.\n",
      "===> Epoch[1](880/5770): Loss: 573.7708 || Time: 0.3412 sec.\n",
      "===> Epoch[1](900/5770): Loss: 560.6969 || Time: 0.3492 sec.\n",
      "===> Epoch[1](920/5770): Loss: 353.0998 || Time: 0.3303 sec.\n",
      "===> Epoch[1](940/5770): Loss: 520.0781 || Time: 0.3324 sec.\n",
      "===> Epoch[1](960/5770): Loss: 186.1271 || Time: 0.3312 sec.\n",
      "===> Epoch[1](980/5770): Loss: 577.6762 || Time: 0.3317 sec.\n",
      "===> Epoch[1](1000/5770): Loss: 188.5262 || Time: 0.3383 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 408.1534, Mean AP = 0.4595, Mean SSIM = 0.9166, Mean PSNR = 22.5916 || Time: 9.5743 sec.\n",
      "===> Epoch[1](1020/5770): Loss: 377.8010 || Time: 0.3289 sec.\n",
      "===> Epoch[1](1040/5770): Loss: 806.4423 || Time: 0.3294 sec.\n",
      "===> Epoch[1](1060/5770): Loss: 231.9881 || Time: 0.3312 sec.\n",
      "===> Epoch[1](1080/5770): Loss: 718.2195 || Time: 0.3329 sec.\n",
      "===> Epoch[1](1100/5770): Loss: 486.9414 || Time: 0.3398 sec.\n",
      "===> Epoch[1](1120/5770): Loss: 397.9572 || Time: 0.3340 sec.\n",
      "===> Epoch[1](1140/5770): Loss: 287.7287 || Time: 0.3399 sec.\n",
      "===> Epoch[1](1160/5770): Loss: 284.9738 || Time: 0.3307 sec.\n",
      "===> Epoch[1](1180/5770): Loss: 337.1797 || Time: 0.3336 sec.\n",
      "===> Epoch[1](1200/5770): Loss: 279.8382 || Time: 0.3353 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 429.7111, Mean AP = 0.4984, Mean SSIM = 0.9198, Mean PSNR = 22.6369 || Time: 9.4548 sec.\n",
      "===> Epoch[1](1220/5770): Loss: 475.1276 || Time: 0.3295 sec.\n",
      "===> Epoch[1](1240/5770): Loss: 435.4516 || Time: 0.3293 sec.\n",
      "===> Epoch[1](1260/5770): Loss: 715.5255 || Time: 0.3296 sec.\n",
      "===> Epoch[1](1280/5770): Loss: 442.0186 || Time: 0.3395 sec.\n",
      "===> Epoch[1](1300/5770): Loss: 284.0311 || Time: 0.3337 sec.\n",
      "===> Epoch[1](1320/5770): Loss: 534.9575 || Time: 0.3296 sec.\n",
      "===> Epoch[1](1340/5770): Loss: 307.9742 || Time: 0.3326 sec.\n",
      "===> Epoch[1](1360/5770): Loss: 218.1498 || Time: 0.3310 sec.\n",
      "===> Epoch[1](1380/5770): Loss: 316.7789 || Time: 0.3355 sec.\n",
      "===> Epoch[1](1400/5770): Loss: 378.7069 || Time: 0.3307 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 403.5744, Mean AP = 0.5065, Mean SSIM = 0.9303, Mean PSNR = 22.8630 || Time: 9.5204 sec.\n",
      "===> Epoch[1](1420/5770): Loss: 425.8749 || Time: 0.3402 sec.\n",
      "===> Epoch[1](1440/5770): Loss: 332.9485 || Time: 0.3345 sec.\n",
      "===> Epoch[1](1460/5770): Loss: 422.2801 || Time: 0.3389 sec.\n",
      "===> Epoch[1](1480/5770): Loss: 297.7048 || Time: 0.3395 sec.\n",
      "===> Epoch[1](1500/5770): Loss: 459.6888 || Time: 0.3664 sec.\n",
      "===> Epoch[1](1520/5770): Loss: 328.4379 || Time: 0.3390 sec.\n",
      "===> Epoch[1](1540/5770): Loss: 325.8024 || Time: 0.3398 sec.\n",
      "===> Epoch[1](1560/5770): Loss: 524.2866 || Time: 0.3429 sec.\n",
      "===> Epoch[1](1580/5770): Loss: 200.1355 || Time: 0.3411 sec.\n",
      "===> Epoch[1](1600/5770): Loss: 149.1746 || Time: 0.3383 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 403.0453, Mean AP = 0.5177, Mean SSIM = 0.9347, Mean PSNR = 23.1857 || Time: 9.5642 sec.\n",
      "===> Epoch[1](1620/5770): Loss: 463.0186 || Time: 0.3274 sec.\n",
      "===> Epoch[1](1640/5770): Loss: 555.2119 || Time: 0.3356 sec.\n",
      "===> Epoch[1](1660/5770): Loss: 211.9903 || Time: 0.3275 sec.\n",
      "===> Epoch[1](1680/5770): Loss: 337.4596 || Time: 0.3365 sec.\n",
      "===> Epoch[1](1700/5770): Loss: 433.5390 || Time: 0.3326 sec.\n",
      "===> Epoch[1](1720/5770): Loss: 502.8797 || Time: 0.3301 sec.\n",
      "===> Epoch[1](1740/5770): Loss: 726.5459 || Time: 0.3315 sec.\n",
      "===> Epoch[1](1760/5770): Loss: 369.2435 || Time: 0.3354 sec.\n",
      "===> Epoch[1](1780/5770): Loss: 437.9332 || Time: 0.3339 sec.\n",
      "===> Epoch[1](1800/5770): Loss: 194.9157 || Time: 0.3305 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 391.5323, Mean AP = 0.5399, Mean SSIM = 0.9180, Mean PSNR = 23.1028 || Time: 9.6350 sec.\n",
      "===> Epoch[1](1820/5770): Loss: 163.1175 || Time: 0.3382 sec.\n",
      "===> Epoch[1](1840/5770): Loss: 540.7472 || Time: 0.3356 sec.\n",
      "===> Epoch[1](1860/5770): Loss: 365.2462 || Time: 0.3320 sec.\n",
      "===> Epoch[1](1880/5770): Loss: 310.4807 || Time: 0.3417 sec.\n",
      "===> Epoch[1](1900/5770): Loss: 254.7354 || Time: 0.3364 sec.\n",
      "===> Epoch[1](1920/5770): Loss: 370.7244 || Time: 0.3482 sec.\n",
      "===> Epoch[1](1940/5770): Loss: 198.8716 || Time: 0.3340 sec.\n",
      "===> Epoch[1](1960/5770): Loss: 260.2040 || Time: 0.3328 sec.\n",
      "===> Epoch[1](1980/5770): Loss: 314.6552 || Time: 0.3296 sec.\n",
      "===> Epoch[1](2000/5770): Loss: 340.2466 || Time: 0.3471 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 356.7706, Mean AP = 0.5349, Mean SSIM = 0.9071, Mean PSNR = 22.8267 || Time: 9.5602 sec.\n",
      "Saving state, iter: 2000\n",
      "===> Epoch[1](2020/5770): Loss: 233.9070 || Time: 0.3286 sec.\n",
      "===> Epoch[1](2040/5770): Loss: 689.0413 || Time: 0.3344 sec.\n",
      "===> Epoch[1](2060/5770): Loss: 356.7833 || Time: 0.3290 sec.\n",
      "===> Epoch[1](2080/5770): Loss: 281.1031 || Time: 0.3324 sec.\n",
      "===> Epoch[1](2100/5770): Loss: 308.0135 || Time: 0.3622 sec.\n",
      "===> Epoch[1](2120/5770): Loss: 217.3339 || Time: 0.3298 sec.\n",
      "===> Epoch[1](2140/5770): Loss: 347.1870 || Time: 0.3332 sec.\n",
      "===> Epoch[1](2160/5770): Loss: 393.2952 || Time: 0.3290 sec.\n",
      "===> Epoch[1](2180/5770): Loss: 803.9673 || Time: 0.3328 sec.\n",
      "===> Epoch[1](2200/5770): Loss: 578.8939 || Time: 0.3360 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 446.5489, Mean AP = 0.4838, Mean SSIM = 0.9068, Mean PSNR = 22.2589 || Time: 9.6375 sec.\n",
      "===> Epoch[1](2220/5770): Loss: 271.4365 || Time: 0.3292 sec.\n",
      "===> Epoch[1](2240/5770): Loss: 342.4503 || Time: 0.3350 sec.\n",
      "===> Epoch[1](2260/5770): Loss: 200.6207 || Time: 0.3286 sec.\n",
      "===> Epoch[1](2280/5770): Loss: 531.2938 || Time: 0.3367 sec.\n",
      "===> Epoch[1](2300/5770): Loss: 393.6448 || Time: 0.3555 sec.\n",
      "===> Epoch[1](2320/5770): Loss: 179.0417 || Time: 0.3377 sec.\n",
      "===> Epoch[1](2340/5770): Loss: 646.2573 || Time: 0.3355 sec.\n",
      "===> Epoch[1](2360/5770): Loss: 159.0736 || Time: 0.3316 sec.\n",
      "===> Epoch[1](2380/5770): Loss: 431.9514 || Time: 0.3577 sec.\n",
      "===> Epoch[1](2400/5770): Loss: 245.7224 || Time: 0.3365 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 372.4469, Mean AP = 0.4935, Mean SSIM = 0.9406, Mean PSNR = 23.7286 || Time: 9.5708 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[1](2420/5770): Loss: 184.5890 || Time: 0.3307 sec.\n",
      "===> Epoch[1](2440/5770): Loss: 627.2442 || Time: 0.3297 sec.\n",
      "===> Epoch[1](2460/5770): Loss: 149.3141 || Time: 0.3317 sec.\n",
      "===> Epoch[1](2480/5770): Loss: 481.4237 || Time: 0.3294 sec.\n",
      "===> Epoch[1](2500/5770): Loss: 192.5788 || Time: 0.3358 sec.\n",
      "===> Epoch[1](2520/5770): Loss: 398.8860 || Time: 0.3312 sec.\n",
      "===> Epoch[1](2540/5770): Loss: 487.9543 || Time: 0.3312 sec.\n",
      "===> Epoch[1](2560/5770): Loss: 661.5037 || Time: 0.3316 sec.\n",
      "===> Epoch[1](2580/5770): Loss: 713.0932 || Time: 0.3372 sec.\n",
      "===> Epoch[1](2600/5770): Loss: 256.8686 || Time: 0.3480 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 322.1776, Mean AP = 0.5108, Mean SSIM = 0.9417, Mean PSNR = 23.7460 || Time: 9.6381 sec.\n",
      "===> Epoch[1](2620/5770): Loss: 125.0689 || Time: 0.3278 sec.\n",
      "===> Epoch[1](2640/5770): Loss: 287.2076 || Time: 0.3392 sec.\n",
      "===> Epoch[1](2660/5770): Loss: 188.7117 || Time: 0.3385 sec.\n",
      "===> Epoch[1](2680/5770): Loss: 524.3151 || Time: 0.3328 sec.\n",
      "===> Epoch[1](2700/5770): Loss: 351.2458 || Time: 0.3404 sec.\n",
      "===> Epoch[1](2720/5770): Loss: 439.6767 || Time: 0.3412 sec.\n",
      "===> Epoch[1](2740/5770): Loss: 316.3333 || Time: 0.3327 sec.\n",
      "===> Epoch[1](2760/5770): Loss: 146.8237 || Time: 0.3336 sec.\n",
      "===> Epoch[1](2780/5770): Loss: 581.3741 || Time: 0.3317 sec.\n",
      "===> Epoch[1](2800/5770): Loss: 212.8961 || Time: 0.3389 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 331.0935, Mean AP = 0.5092, Mean SSIM = 0.9426, Mean PSNR = 23.8884 || Time: 9.6260 sec.\n",
      "===> Epoch[1](2820/5770): Loss: 270.5901 || Time: 0.3372 sec.\n",
      "===> Epoch[1](2840/5770): Loss: 151.6162 || Time: 0.3370 sec.\n",
      "===> Epoch[1](2860/5770): Loss: 260.4518 || Time: 0.3306 sec.\n",
      "===> Epoch[1](2880/5770): Loss: 421.4187 || Time: 0.3310 sec.\n",
      "===> Epoch[1](2900/5770): Loss: 969.6365 || Time: 0.3318 sec.\n",
      "===> Epoch[1](2920/5770): Loss: 459.3438 || Time: 0.3336 sec.\n",
      "===> Epoch[1](2940/5770): Loss: 769.6938 || Time: 0.3421 sec.\n",
      "===> Epoch[1](2960/5770): Loss: 420.2389 || Time: 0.3410 sec.\n",
      "===> Epoch[1](2980/5770): Loss: 342.7105 || Time: 0.3418 sec.\n",
      "===> Epoch[1](3000/5770): Loss: 350.1801 || Time: 0.3272 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 348.0931, Mean AP = 0.4932, Mean SSIM = 0.9280, Mean PSNR = 21.8333 || Time: 9.6264 sec.\n",
      "===> Epoch[1](3020/5770): Loss: 462.1788 || Time: 0.3287 sec.\n",
      "===> Epoch[1](3040/5770): Loss: 376.2070 || Time: 0.3293 sec.\n",
      "===> Epoch[1](3060/5770): Loss: 505.8056 || Time: 0.3303 sec.\n",
      "===> Epoch[1](3080/5770): Loss: 351.2485 || Time: 0.3355 sec.\n",
      "===> Epoch[1](3100/5770): Loss: 562.4863 || Time: 0.3309 sec.\n",
      "===> Epoch[1](3120/5770): Loss: 106.6801 || Time: 0.3456 sec.\n",
      "===> Epoch[1](3140/5770): Loss: 206.3624 || Time: 0.3427 sec.\n",
      "===> Epoch[1](3160/5770): Loss: 216.7407 || Time: 0.3292 sec.\n",
      "===> Epoch[1](3180/5770): Loss: 428.0634 || Time: 0.3367 sec.\n",
      "===> Epoch[1](3200/5770): Loss: 379.1083 || Time: 0.3371 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 332.7974, Mean AP = 0.5510, Mean SSIM = 0.9413, Mean PSNR = 23.8497 || Time: 9.6314 sec.\n",
      "===> Epoch[1](3220/5770): Loss: 228.5972 || Time: 0.3298 sec.\n",
      "===> Epoch[1](3240/5770): Loss: 294.5322 || Time: 0.3303 sec.\n",
      "===> Epoch[1](3260/5770): Loss: 682.8652 || Time: 0.3297 sec.\n",
      "===> Epoch[1](3280/5770): Loss: 169.7320 || Time: 0.3393 sec.\n",
      "===> Epoch[1](3300/5770): Loss: 272.6495 || Time: 0.3279 sec.\n",
      "===> Epoch[1](3320/5770): Loss: 369.9197 || Time: 0.3356 sec.\n",
      "===> Epoch[1](3340/5770): Loss: 331.4063 || Time: 0.3317 sec.\n",
      "===> Epoch[1](3360/5770): Loss: 293.7408 || Time: 0.3416 sec.\n",
      "===> Epoch[1](3380/5770): Loss: 380.3478 || Time: 0.3339 sec.\n",
      "===> Epoch[1](3400/5770): Loss: 196.6253 || Time: 0.3393 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 309.2173, Mean AP = 0.5612, Mean SSIM = 0.9440, Mean PSNR = 24.0189 || Time: 9.6820 sec.\n",
      "===> Epoch[1](3420/5770): Loss: 325.7778 || Time: 0.3294 sec.\n",
      "===> Epoch[1](3440/5770): Loss: 358.1546 || Time: 0.3295 sec.\n",
      "===> Epoch[1](3460/5770): Loss: 134.3128 || Time: 0.3297 sec.\n",
      "===> Epoch[1](3480/5770): Loss: 78.7956 || Time: 0.3346 sec.\n",
      "===> Epoch[1](3500/5770): Loss: 282.7333 || Time: 0.3378 sec.\n",
      "===> Epoch[1](3520/5770): Loss: 344.5688 || Time: 0.3453 sec.\n",
      "===> Epoch[1](3540/5770): Loss: 129.2272 || Time: 0.3314 sec.\n",
      "===> Epoch[1](3560/5770): Loss: 180.9619 || Time: 0.3354 sec.\n",
      "===> Epoch[1](3580/5770): Loss: 283.7510 || Time: 0.3353 sec.\n",
      "===> Epoch[1](3600/5770): Loss: 206.4560 || Time: 0.3292 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 293.7153, Mean AP = 0.5491, Mean SSIM = 0.9406, Mean PSNR = 23.9870 || Time: 9.6380 sec.\n",
      "===> Epoch[1](3620/5770): Loss: 391.7068 || Time: 0.3279 sec.\n",
      "===> Epoch[1](3640/5770): Loss: 227.1829 || Time: 0.3298 sec.\n",
      "===> Epoch[1](3660/5770): Loss: 181.4864 || Time: 0.3306 sec.\n",
      "===> Epoch[1](3680/5770): Loss: 434.7307 || Time: 0.3341 sec.\n",
      "===> Epoch[1](3700/5770): Loss: 215.3569 || Time: 0.3300 sec.\n",
      "===> Epoch[1](3720/5770): Loss: 680.7413 || Time: 0.3346 sec.\n",
      "===> Epoch[1](3740/5770): Loss: 335.9102 || Time: 0.3410 sec.\n",
      "===> Epoch[1](3760/5770): Loss: 228.3451 || Time: 0.3632 sec.\n",
      "===> Epoch[1](3780/5770): Loss: 296.7610 || Time: 0.3362 sec.\n",
      "===> Epoch[1](3800/5770): Loss: 120.9141 || Time: 0.3315 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 289.1584, Mean AP = 0.5779, Mean SSIM = 0.9419, Mean PSNR = 23.0108 || Time: 9.6334 sec.\n",
      "===> Epoch[1](3820/5770): Loss: 156.3476 || Time: 0.3298 sec.\n",
      "===> Epoch[1](3840/5770): Loss: 197.5958 || Time: 0.3390 sec.\n",
      "===> Epoch[1](3860/5770): Loss: 207.8893 || Time: 0.3332 sec.\n",
      "===> Epoch[1](3880/5770): Loss: 217.5730 || Time: 0.3350 sec.\n",
      "===> Epoch[1](3900/5770): Loss: 275.2466 || Time: 0.3324 sec.\n",
      "===> Epoch[1](3920/5770): Loss: 226.2407 || Time: 0.3424 sec.\n",
      "===> Epoch[1](3940/5770): Loss: 87.5209 || Time: 0.3357 sec.\n",
      "===> Epoch[1](3960/5770): Loss: 379.1005 || Time: 0.3306 sec.\n",
      "===> Epoch[1](3980/5770): Loss: 378.3321 || Time: 0.3319 sec.\n",
      "===> Epoch[1](4000/5770): Loss: 300.0568 || Time: 0.3311 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 296.5966, Mean AP = 0.5777, Mean SSIM = 0.9459, Mean PSNR = 24.1189 || Time: 9.6640 sec.\n",
      "Saving state, iter: 4000\n",
      "===> Epoch[1](4020/5770): Loss: 96.3712 || Time: 0.3274 sec.\n",
      "===> Epoch[1](4040/5770): Loss: 383.7235 || Time: 0.3338 sec.\n",
      "===> Epoch[1](4060/5770): Loss: 170.9076 || Time: 0.3371 sec.\n",
      "===> Epoch[1](4080/5770): Loss: 286.6953 || Time: 0.3288 sec.\n",
      "===> Epoch[1](4100/5770): Loss: 107.8619 || Time: 0.3398 sec.\n",
      "===> Epoch[1](4120/5770): Loss: 286.1908 || Time: 0.3463 sec.\n",
      "===> Epoch[1](4140/5770): Loss: 188.1546 || Time: 0.3334 sec.\n",
      "===> Epoch[1](4160/5770): Loss: 177.4723 || Time: 0.3318 sec.\n",
      "===> Epoch[1](4180/5770): Loss: 328.7386 || Time: 0.3321 sec.\n",
      "===> Epoch[1](4200/5770): Loss: 325.8482 || Time: 0.3582 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 284.2969, Mean AP = 0.5205, Mean SSIM = 0.9438, Mean PSNR = 23.1621 || Time: 9.5495 sec.\n",
      "===> Epoch[1](4220/5770): Loss: 325.9403 || Time: 0.3305 sec.\n",
      "===> Epoch[1](4240/5770): Loss: 198.8826 || Time: 0.3341 sec.\n",
      "===> Epoch[1](4260/5770): Loss: 298.1550 || Time: 0.3302 sec.\n",
      "===> Epoch[1](4280/5770): Loss: 170.2551 || Time: 0.3396 sec.\n",
      "===> Epoch[1](4300/5770): Loss: 283.0724 || Time: 0.3358 sec.\n",
      "===> Epoch[1](4320/5770): Loss: 457.0640 || Time: 0.3363 sec.\n",
      "===> Epoch[1](4340/5770): Loss: 629.8873 || Time: 0.3388 sec.\n",
      "===> Epoch[1](4360/5770): Loss: 182.8180 || Time: 0.3322 sec.\n",
      "===> Epoch[1](4380/5770): Loss: 116.2335 || Time: 0.3571 sec.\n",
      "===> Epoch[1](4400/5770): Loss: 609.3442 || Time: 0.3298 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 325.0683, Mean AP = 0.5281, Mean SSIM = 0.9464, Mean PSNR = 24.1378 || Time: 9.4900 sec.\n",
      "===> Epoch[1](4420/5770): Loss: 164.2846 || Time: 0.3289 sec.\n",
      "===> Epoch[1](4440/5770): Loss: 203.3678 || Time: 0.3298 sec.\n",
      "===> Epoch[1](4460/5770): Loss: 229.6826 || Time: 0.3305 sec.\n",
      "===> Epoch[1](4480/5770): Loss: 468.0698 || Time: 0.3374 sec.\n",
      "===> Epoch[1](4500/5770): Loss: 898.8415 || Time: 0.3322 sec.\n",
      "===> Epoch[1](4520/5770): Loss: 3591.0261 || Time: 0.3331 sec.\n",
      "===> Epoch[1](4540/5770): Loss: 2286.8999 || Time: 0.3319 sec.\n",
      "===> Epoch[1](4560/5770): Loss: 596.1373 || Time: 0.3361 sec.\n",
      "===> Epoch[1](4580/5770): Loss: 405.3348 || Time: 0.3324 sec.\n",
      "===> Epoch[1](4600/5770): Loss: 455.6951 || Time: 0.3413 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 870.6057, Mean AP = 0.4191, Mean SSIM = 0.9061, Mean PSNR = 22.4285 || Time: 9.6173 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[1](4620/5770): Loss: 466.9964 || Time: 0.3277 sec.\n",
      "===> Epoch[1](4640/5770): Loss: 474.2275 || Time: 0.3305 sec.\n",
      "===> Epoch[1](4660/5770): Loss: 217.1351 || Time: 0.3301 sec.\n",
      "===> Epoch[1](4680/5770): Loss: 172.2801 || Time: 0.3326 sec.\n",
      "===> Epoch[1](4700/5770): Loss: 359.2838 || Time: 0.3323 sec.\n",
      "===> Epoch[1](4720/5770): Loss: 208.5593 || Time: 0.3356 sec.\n",
      "===> Epoch[1](4740/5770): Loss: 167.7452 || Time: 0.3328 sec.\n",
      "===> Epoch[1](4760/5770): Loss: 561.1818 || Time: 0.3379 sec.\n",
      "===> Epoch[1](4780/5770): Loss: 162.2308 || Time: 0.3323 sec.\n",
      "===> Epoch[1](4800/5770): Loss: 401.7009 || Time: 0.3342 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 354.3392, Mean AP = 0.4939, Mean SSIM = 0.9193, Mean PSNR = 22.9220 || Time: 9.5738 sec.\n",
      "===> Epoch[1](4820/5770): Loss: 159.2100 || Time: 0.3292 sec.\n",
      "===> Epoch[1](4840/5770): Loss: 374.7780 || Time: 0.3300 sec.\n",
      "===> Epoch[1](4860/5770): Loss: 495.8117 || Time: 0.3299 sec.\n",
      "===> Epoch[1](4880/5770): Loss: 639.4796 || Time: 0.3361 sec.\n",
      "===> Epoch[1](4900/5770): Loss: 282.1270 || Time: 0.3306 sec.\n",
      "===> Epoch[1](4920/5770): Loss: 198.4024 || Time: 0.3318 sec.\n",
      "===> Epoch[1](4940/5770): Loss: 318.2011 || Time: 0.3333 sec.\n",
      "===> Epoch[1](4960/5770): Loss: 277.8399 || Time: 0.3400 sec.\n",
      "===> Epoch[1](4980/5770): Loss: 405.2389 || Time: 0.3323 sec.\n",
      "===> Epoch[1](5000/5770): Loss: 208.0584 || Time: 0.3302 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 352.5143, Mean AP = 0.4830, Mean SSIM = 0.9383, Mean PSNR = 23.7271 || Time: 9.6572 sec.\n",
      "===> Epoch[1](5020/5770): Loss: 462.5541 || Time: 0.3375 sec.\n",
      "===> Epoch[1](5040/5770): Loss: 105.2883 || Time: 0.3297 sec.\n",
      "===> Epoch[1](5060/5770): Loss: 220.6807 || Time: 0.3501 sec.\n",
      "===> Epoch[1](5080/5770): Loss: 297.8076 || Time: 0.3337 sec.\n",
      "===> Epoch[1](5100/5770): Loss: 729.8150 || Time: 0.3305 sec.\n",
      "===> Epoch[1](5120/5770): Loss: 122.4199 || Time: 0.3382 sec.\n",
      "===> Epoch[1](5140/5770): Loss: 435.8789 || Time: 0.3321 sec.\n",
      "===> Epoch[1](5160/5770): Loss: 108.3330 || Time: 0.3401 sec.\n",
      "===> Epoch[1](5180/5770): Loss: 429.0863 || Time: 0.3430 sec.\n",
      "===> Epoch[1](5200/5770): Loss: 142.2031 || Time: 0.3298 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 321.3683, Mean AP = 0.4771, Mean SSIM = 0.9441, Mean PSNR = 24.0588 || Time: 9.6770 sec.\n",
      "===> Epoch[1](5220/5770): Loss: 152.3927 || Time: 0.3278 sec.\n",
      "===> Epoch[1](5240/5770): Loss: 280.1388 || Time: 0.3297 sec.\n",
      "===> Epoch[1](5260/5770): Loss: 324.5659 || Time: 0.3449 sec.\n",
      "===> Epoch[1](5280/5770): Loss: 325.4227 || Time: 0.3377 sec.\n",
      "===> Epoch[1](5300/5770): Loss: 197.8322 || Time: 0.3326 sec.\n",
      "===> Epoch[1](5320/5770): Loss: 381.5499 || Time: 0.3364 sec.\n",
      "===> Epoch[1](5340/5770): Loss: 193.4670 || Time: 0.3405 sec.\n",
      "===> Epoch[1](5360/5770): Loss: 65.4257 || Time: 0.3307 sec.\n",
      "===> Epoch[1](5380/5770): Loss: 236.2732 || Time: 0.3304 sec.\n",
      "===> Epoch[1](5400/5770): Loss: 146.5195 || Time: 0.3330 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 315.8154, Mean AP = 0.5034, Mean SSIM = 0.9447, Mean PSNR = 24.0498 || Time: 9.8082 sec.\n",
      "===> Epoch[1](5420/5770): Loss: 244.4171 || Time: 0.3300 sec.\n",
      "===> Epoch[1](5440/5770): Loss: 403.6117 || Time: 0.3415 sec.\n",
      "===> Epoch[1](5460/5770): Loss: 66.3190 || Time: 0.3331 sec.\n",
      "===> Epoch[1](5480/5770): Loss: 283.2242 || Time: 0.3327 sec.\n",
      "===> Epoch[1](5500/5770): Loss: 526.6489 || Time: 0.3325 sec.\n",
      "===> Epoch[1](5520/5770): Loss: 301.4435 || Time: 0.3317 sec.\n",
      "===> Epoch[1](5540/5770): Loss: 433.5413 || Time: 0.3574 sec.\n",
      "===> Epoch[1](5560/5770): Loss: 215.2540 || Time: 0.3399 sec.\n",
      "===> Epoch[1](5580/5770): Loss: 177.0685 || Time: 0.3297 sec.\n",
      "===> Epoch[1](5600/5770): Loss: 426.5542 || Time: 0.3466 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 279.6250, Mean AP = 0.5140, Mean SSIM = 0.9470, Mean PSNR = 24.2795 || Time: 9.7491 sec.\n",
      "===> Epoch 1 Complete: Avg. Loss: 244.8336 || Time: 2153.0738 sec.\n",
      "===> Epoch[2](20/5770): Loss: 168.7797 || Time: 0.3300 sec.\n",
      "===> Epoch[2](40/5770): Loss: 142.6547 || Time: 0.3296 sec.\n",
      "===> Epoch[2](60/5770): Loss: 311.4705 || Time: 0.3361 sec.\n",
      "===> Epoch[2](80/5770): Loss: 181.4846 || Time: 0.3332 sec.\n",
      "===> Epoch[2](100/5770): Loss: 407.7651 || Time: 0.3296 sec.\n",
      "===> Epoch[2](120/5770): Loss: 148.8757 || Time: 0.3484 sec.\n",
      "===> Epoch[2](140/5770): Loss: 483.8548 || Time: 0.3356 sec.\n",
      "===> Epoch[2](160/5770): Loss: 317.4525 || Time: 0.3315 sec.\n",
      "===> Epoch[2](180/5770): Loss: 396.9364 || Time: 0.3398 sec.\n",
      "===> Epoch[2](200/5770): Loss: 269.2417 || Time: 0.3335 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 265.5508, Mean AP = 0.5108, Mean SSIM = 0.9476, Mean PSNR = 24.3269 || Time: 9.7318 sec.\n",
      "===> Epoch[2](220/5770): Loss: 128.0208 || Time: 0.3308 sec.\n",
      "===> Epoch[2](240/5770): Loss: 273.3399 || Time: 0.3379 sec.\n",
      "===> Epoch[2](260/5770): Loss: 293.0811 || Time: 0.3313 sec.\n",
      "===> Epoch[2](280/5770): Loss: 170.4096 || Time: 0.3332 sec.\n",
      "===> Epoch[2](300/5770): Loss: 190.9110 || Time: 0.3449 sec.\n",
      "===> Epoch[2](320/5770): Loss: 204.9106 || Time: 0.3349 sec.\n",
      "===> Epoch[2](340/5770): Loss: 239.5284 || Time: 0.3374 sec.\n",
      "===> Epoch[2](360/5770): Loss: 268.0739 || Time: 0.3340 sec.\n",
      "===> Epoch[2](380/5770): Loss: 247.4983 || Time: 0.3337 sec.\n",
      "===> Epoch[2](400/5770): Loss: 379.2885 || Time: 0.3315 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 268.5332, Mean AP = 0.5311, Mean SSIM = 0.9476, Mean PSNR = 24.3231 || Time: 9.6759 sec.\n",
      "===> Epoch[2](420/5770): Loss: 143.7766 || Time: 0.3273 sec.\n",
      "===> Epoch[2](440/5770): Loss: 507.7763 || Time: 0.3400 sec.\n",
      "===> Epoch[2](460/5770): Loss: 217.1681 || Time: 0.3379 sec.\n",
      "===> Epoch[2](480/5770): Loss: 81.8040 || Time: 0.3324 sec.\n",
      "===> Epoch[2](500/5770): Loss: 205.4247 || Time: 0.3393 sec.\n",
      "===> Epoch[2](520/5770): Loss: 267.3392 || Time: 0.3391 sec.\n",
      "===> Epoch[2](540/5770): Loss: 331.8335 || Time: 0.3517 sec.\n",
      "===> Epoch[2](560/5770): Loss: 241.5077 || Time: 0.3410 sec.\n",
      "===> Epoch[2](580/5770): Loss: 322.0255 || Time: 0.3348 sec.\n",
      "===> Epoch[2](600/5770): Loss: 64.9822 || Time: 0.3450 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 268.4899, Mean AP = 0.5120, Mean SSIM = 0.9473, Mean PSNR = 24.3791 || Time: 9.6446 sec.\n",
      "===> Epoch[2](620/5770): Loss: 183.8570 || Time: 0.3307 sec.\n",
      "===> Epoch[2](640/5770): Loss: 227.3847 || Time: 0.3360 sec.\n",
      "===> Epoch[2](660/5770): Loss: 154.9301 || Time: 0.3309 sec.\n",
      "===> Epoch[2](680/5770): Loss: 227.0953 || Time: 0.3308 sec.\n",
      "===> Epoch[2](700/5770): Loss: 311.2517 || Time: 0.3363 sec.\n",
      "===> Epoch[2](720/5770): Loss: 117.6728 || Time: 0.3293 sec.\n",
      "===> Epoch[2](740/5770): Loss: 431.7659 || Time: 0.3404 sec.\n",
      "===> Epoch[2](760/5770): Loss: 333.5228 || Time: 0.3583 sec.\n",
      "===> Epoch[2](780/5770): Loss: 477.8429 || Time: 0.3390 sec.\n",
      "===> Epoch[2](800/5770): Loss: 199.8565 || Time: 0.3424 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 274.0369, Mean AP = 0.5209, Mean SSIM = 0.9489, Mean PSNR = 24.4298 || Time: 9.6169 sec.\n",
      "===> Epoch[2](820/5770): Loss: 369.5543 || Time: 0.3288 sec.\n",
      "===> Epoch[2](840/5770): Loss: 362.7648 || Time: 0.3281 sec.\n",
      "===> Epoch[2](860/5770): Loss: 314.9908 || Time: 0.3302 sec.\n",
      "===> Epoch[2](880/5770): Loss: 229.5383 || Time: 0.3588 sec.\n",
      "===> Epoch[2](900/5770): Loss: 431.3658 || Time: 0.3313 sec.\n",
      "===> Epoch[2](920/5770): Loss: 217.6189 || Time: 0.3426 sec.\n",
      "===> Epoch[2](940/5770): Loss: 376.2950 || Time: 0.3337 sec.\n",
      "===> Epoch[2](960/5770): Loss: 126.0476 || Time: 0.3449 sec.\n",
      "===> Epoch[2](980/5770): Loss: 376.3732 || Time: 0.3516 sec.\n",
      "===> Epoch[2](1000/5770): Loss: 115.6038 || Time: 0.3654 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 268.7688, Mean AP = 0.5206, Mean SSIM = 0.9473, Mean PSNR = 24.4403 || Time: 10.1268 sec.\n",
      "===> Epoch[2](1020/5770): Loss: 286.7667 || Time: 0.3291 sec.\n",
      "===> Epoch[2](1040/5770): Loss: 366.6977 || Time: 0.3404 sec.\n",
      "===> Epoch[2](1060/5770): Loss: 161.9330 || Time: 0.3349 sec.\n",
      "===> Epoch[2](1080/5770): Loss: 632.9285 || Time: 0.3447 sec.\n",
      "===> Epoch[2](1100/5770): Loss: 361.7467 || Time: 0.3561 sec.\n",
      "===> Epoch[2](1120/5770): Loss: 305.4658 || Time: 0.3424 sec.\n",
      "===> Epoch[2](1140/5770): Loss: 183.0693 || Time: 0.3372 sec.\n",
      "===> Epoch[2](1160/5770): Loss: 237.7971 || Time: 0.3318 sec.\n",
      "===> Epoch[2](1180/5770): Loss: 163.4119 || Time: 0.3329 sec.\n",
      "===> Epoch[2](1200/5770): Loss: 184.5061 || Time: 0.3466 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 276.8606, Mean AP = 0.5108, Mean SSIM = 0.9473, Mean PSNR = 24.4083 || Time: 9.5355 sec.\n",
      "===> Epoch[2](1220/5770): Loss: 353.8365 || Time: 0.3297 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[2](1240/5770): Loss: 349.0106 || Time: 0.3297 sec.\n",
      "===> Epoch[2](1260/5770): Loss: 604.3627 || Time: 0.3401 sec.\n",
      "===> Epoch[2](1280/5770): Loss: 335.3168 || Time: 0.3297 sec.\n",
      "===> Epoch[2](1300/5770): Loss: 131.4360 || Time: 0.3319 sec.\n",
      "===> Epoch[2](1320/5770): Loss: 457.6828 || Time: 0.3421 sec.\n",
      "===> Epoch[2](1340/5770): Loss: 227.4641 || Time: 0.3322 sec.\n",
      "===> Epoch[2](1360/5770): Loss: 164.0735 || Time: 0.3313 sec.\n",
      "===> Epoch[2](1380/5770): Loss: 196.7931 || Time: 0.3359 sec.\n",
      "===> Epoch[2](1400/5770): Loss: 279.8923 || Time: 0.3626 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 283.9122, Mean AP = 0.5149, Mean SSIM = 0.9456, Mean PSNR = 24.2699 || Time: 9.7565 sec.\n",
      "===> Epoch[2](1420/5770): Loss: 281.9443 || Time: 0.3301 sec.\n",
      "===> Epoch[2](1440/5770): Loss: 273.9815 || Time: 0.3274 sec.\n",
      "===> Epoch[2](1460/5770): Loss: 340.3619 || Time: 0.3305 sec.\n",
      "===> Epoch[2](1480/5770): Loss: 234.0433 || Time: 0.3351 sec.\n",
      "===> Epoch[2](1500/5770): Loss: 382.6326 || Time: 0.3396 sec.\n",
      "===> Epoch[2](1520/5770): Loss: 222.2000 || Time: 0.3379 sec.\n",
      "===> Epoch[2](1540/5770): Loss: 270.1487 || Time: 0.3597 sec.\n",
      "===> Epoch[2](1560/5770): Loss: 374.9358 || Time: 0.3327 sec.\n",
      "===> Epoch[2](1580/5770): Loss: 134.2378 || Time: 0.3292 sec.\n",
      "===> Epoch[2](1600/5770): Loss: 99.8187 || Time: 0.3286 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 289.1830, Mean AP = 0.5208, Mean SSIM = 0.9445, Mean PSNR = 24.4159 || Time: 9.7716 sec.\n",
      "===> Epoch[2](1620/5770): Loss: 393.2766 || Time: 0.3289 sec.\n",
      "===> Epoch[2](1640/5770): Loss: 406.5800 || Time: 0.3303 sec.\n",
      "===> Epoch[2](1660/5770): Loss: 143.7008 || Time: 0.3314 sec.\n",
      "===> Epoch[2](1680/5770): Loss: 172.5359 || Time: 0.3342 sec.\n",
      "===> Epoch[2](1700/5770): Loss: 365.0715 || Time: 0.3314 sec.\n",
      "===> Epoch[2](1720/5770): Loss: 221.9234 || Time: 0.3578 sec.\n",
      "===> Epoch[2](1740/5770): Loss: 641.1359 || Time: 0.3485 sec.\n",
      "===> Epoch[2](1760/5770): Loss: 374.1969 || Time: 0.3329 sec.\n",
      "===> Epoch[2](1780/5770): Loss: 347.3341 || Time: 0.3401 sec.\n",
      "===> Epoch[2](1800/5770): Loss: 117.3545 || Time: 0.3388 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 281.3711, Mean AP = 0.5354, Mean SSIM = 0.9492, Mean PSNR = 24.5254 || Time: 9.7561 sec.\n",
      "===> Epoch[2](1820/5770): Loss: 143.5860 || Time: 0.3301 sec.\n",
      "===> Epoch[2](1840/5770): Loss: 489.9186 || Time: 0.3311 sec.\n",
      "===> Epoch[2](1860/5770): Loss: 314.5753 || Time: 0.3316 sec.\n",
      "===> Epoch[2](1880/5770): Loss: 204.0201 || Time: 0.3402 sec.\n",
      "===> Epoch[2](1900/5770): Loss: 175.2535 || Time: 0.3292 sec.\n",
      "===> Epoch[2](1920/5770): Loss: 330.7883 || Time: 0.3357 sec.\n",
      "===> Epoch[2](1940/5770): Loss: 153.6077 || Time: 0.3418 sec.\n",
      "===> Epoch[2](1960/5770): Loss: 190.0431 || Time: 0.3344 sec.\n",
      "===> Epoch[2](1980/5770): Loss: 270.8168 || Time: 0.3350 sec.\n",
      "===> Epoch[2](2000/5770): Loss: 278.5987 || Time: 0.3309 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 271.9462, Mean AP = 0.5225, Mean SSIM = 0.9303, Mean PSNR = 24.0116 || Time: 9.7594 sec.\n",
      "Saving state, iter: 2000\n",
      "===> Epoch[2](2020/5770): Loss: 170.0520 || Time: 0.3312 sec.\n",
      "===> Epoch[2](2040/5770): Loss: 551.4741 || Time: 0.3290 sec.\n",
      "===> Epoch[2](2060/5770): Loss: 222.5255 || Time: 0.3294 sec.\n",
      "===> Epoch[2](2080/5770): Loss: 151.8615 || Time: 0.3294 sec.\n",
      "===> Epoch[2](2100/5770): Loss: 215.6639 || Time: 0.3350 sec.\n",
      "===> Epoch[2](2120/5770): Loss: 176.2620 || Time: 0.3451 sec.\n",
      "===> Epoch[2](2140/5770): Loss: 290.5043 || Time: 0.3334 sec.\n",
      "===> Epoch[2](2160/5770): Loss: 313.4870 || Time: 0.3421 sec.\n",
      "===> Epoch[2](2180/5770): Loss: 308.6731 || Time: 0.3295 sec.\n",
      "===> Epoch[2](2200/5770): Loss: 423.6970 || Time: 0.3366 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 291.7405, Mean AP = 0.5394, Mean SSIM = 0.9503, Mean PSNR = 24.4905 || Time: 9.7610 sec.\n",
      "===> Epoch[2](2220/5770): Loss: 137.5738 || Time: 0.3382 sec.\n",
      "===> Epoch[2](2240/5770): Loss: 247.1836 || Time: 0.3325 sec.\n",
      "===> Epoch[2](2260/5770): Loss: 151.1178 || Time: 0.3337 sec.\n",
      "===> Epoch[2](2280/5770): Loss: 480.8765 || Time: 0.3322 sec.\n",
      "===> Epoch[2](2300/5770): Loss: 332.6721 || Time: 0.3545 sec.\n",
      "===> Epoch[2](2320/5770): Loss: 136.8831 || Time: 0.3381 sec.\n",
      "===> Epoch[2](2340/5770): Loss: 563.2833 || Time: 0.3314 sec.\n",
      "===> Epoch[2](2360/5770): Loss: 147.9579 || Time: 0.3333 sec.\n",
      "===> Epoch[2](2380/5770): Loss: 373.3315 || Time: 0.3303 sec.\n",
      "===> Epoch[2](2400/5770): Loss: 187.0550 || Time: 0.3573 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 299.9220, Mean AP = 0.5418, Mean SSIM = 0.9505, Mean PSNR = 24.6270 || Time: 9.7445 sec.\n",
      "===> Epoch[2](2420/5770): Loss: 137.4406 || Time: 0.3286 sec.\n",
      "===> Epoch[2](2440/5770): Loss: 546.8117 || Time: 0.3298 sec.\n",
      "===> Epoch[2](2460/5770): Loss: 107.1907 || Time: 0.3529 sec.\n",
      "===> Epoch[2](2480/5770): Loss: 457.9833 || Time: 0.3358 sec.\n",
      "===> Epoch[2](2500/5770): Loss: 172.5837 || Time: 0.3387 sec.\n",
      "===> Epoch[2](2520/5770): Loss: 343.0510 || Time: 0.3338 sec.\n",
      "===> Epoch[2](2540/5770): Loss: 423.3083 || Time: 0.3351 sec.\n",
      "===> Epoch[2](2560/5770): Loss: 568.8594 || Time: 0.3346 sec.\n",
      "===> Epoch[2](2580/5770): Loss: 663.7766 || Time: 0.3322 sec.\n",
      "===> Epoch[2](2600/5770): Loss: 204.5319 || Time: 0.3315 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 272.8905, Mean AP = 0.5336, Mean SSIM = 0.9444, Mean PSNR = 24.3098 || Time: 9.7181 sec.\n",
      "===> Epoch[2](2620/5770): Loss: 90.6530 || Time: 0.3334 sec.\n",
      "===> Epoch[2](2640/5770): Loss: 235.6848 || Time: 0.3283 sec.\n",
      "===> Epoch[2](2660/5770): Loss: 146.6695 || Time: 0.3330 sec.\n",
      "===> Epoch[2](2680/5770): Loss: 435.1299 || Time: 0.3415 sec.\n",
      "===> Epoch[2](2700/5770): Loss: 264.3263 || Time: 0.3293 sec.\n",
      "===> Epoch[2](2720/5770): Loss: 368.3376 || Time: 0.3493 sec.\n",
      "===> Epoch[2](2740/5770): Loss: 293.0947 || Time: 0.3300 sec.\n",
      "===> Epoch[2](2760/5770): Loss: 112.1198 || Time: 0.3372 sec.\n",
      "===> Epoch[2](2780/5770): Loss: 536.7615 || Time: 0.3359 sec.\n",
      "===> Epoch[2](2800/5770): Loss: 168.4099 || Time: 0.3388 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 285.5017, Mean AP = 0.5721, Mean SSIM = 0.9507, Mean PSNR = 24.3971 || Time: 9.7869 sec.\n",
      "===> Epoch[2](2820/5770): Loss: 258.4376 || Time: 0.3307 sec.\n",
      "===> Epoch[2](2840/5770): Loss: 141.1650 || Time: 0.3299 sec.\n",
      "===> Epoch[2](2860/5770): Loss: 257.4302 || Time: 0.3327 sec.\n",
      "===> Epoch[2](2880/5770): Loss: 537.1723 || Time: 0.3334 sec.\n",
      "===> Epoch[2](2900/5770): Loss: 918.7584 || Time: 0.3291 sec.\n",
      "===> Epoch[2](2920/5770): Loss: 386.9465 || Time: 0.3380 sec.\n",
      "===> Epoch[2](2940/5770): Loss: 633.8607 || Time: 0.3447 sec.\n",
      "===> Epoch[2](2960/5770): Loss: 313.4970 || Time: 0.3296 sec.\n",
      "===> Epoch[2](2980/5770): Loss: 282.5161 || Time: 0.3326 sec.\n",
      "===> Epoch[2](3000/5770): Loss: 227.7932 || Time: 0.3656 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 307.4804, Mean AP = 0.5219, Mean SSIM = 0.9511, Mean PSNR = 24.5689 || Time: 9.7949 sec.\n",
      "===> Epoch[2](3020/5770): Loss: 360.3765 || Time: 0.3517 sec.\n",
      "===> Epoch[2](3040/5770): Loss: 254.7004 || Time: 0.3350 sec.\n",
      "===> Epoch[2](3060/5770): Loss: 427.9175 || Time: 0.3392 sec.\n",
      "===> Epoch[2](3080/5770): Loss: 299.4995 || Time: 0.3323 sec.\n",
      "===> Epoch[2](3100/5770): Loss: 438.0302 || Time: 0.3395 sec.\n",
      "===> Epoch[2](3120/5770): Loss: 87.6783 || Time: 0.3284 sec.\n",
      "===> Epoch[2](3140/5770): Loss: 156.7581 || Time: 0.3372 sec.\n",
      "===> Epoch[2](3160/5770): Loss: 167.5749 || Time: 0.3384 sec.\n",
      "===> Epoch[2](3180/5770): Loss: 371.0205 || Time: 0.3324 sec.\n",
      "===> Epoch[2](3200/5770): Loss: 290.8080 || Time: 0.3539 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 265.6754, Mean AP = 0.5751, Mean SSIM = 0.9516, Mean PSNR = 24.7757 || Time: 9.6790 sec.\n",
      "===> Epoch[2](3220/5770): Loss: 169.2915 || Time: 0.3267 sec.\n",
      "===> Epoch[2](3240/5770): Loss: 262.8936 || Time: 0.3282 sec.\n",
      "===> Epoch[2](3260/5770): Loss: 602.6592 || Time: 0.3314 sec.\n",
      "===> Epoch[2](3280/5770): Loss: 138.3996 || Time: 0.3328 sec.\n",
      "===> Epoch[2](3300/5770): Loss: 227.9402 || Time: 0.3343 sec.\n",
      "===> Epoch[2](3320/5770): Loss: 298.9377 || Time: 0.3378 sec.\n",
      "===> Epoch[2](3340/5770): Loss: 278.8023 || Time: 0.3315 sec.\n",
      "===> Epoch[2](3360/5770): Loss: 225.4612 || Time: 0.3307 sec.\n",
      "===> Epoch[2](3380/5770): Loss: 322.3192 || Time: 0.3306 sec.\n",
      "===> Epoch[2](3400/5770): Loss: 180.0376 || Time: 0.3396 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 258.8695, Mean AP = 0.5278, Mean SSIM = 0.9519, Mean PSNR = 24.8063 || Time: 9.7081 sec.\n",
      "===> Epoch[2](3420/5770): Loss: 310.0287 || Time: 0.3291 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[2](3440/5770): Loss: 293.3805 || Time: 0.3345 sec.\n",
      "===> Epoch[2](3460/5770): Loss: 90.4166 || Time: 0.3296 sec.\n",
      "===> Epoch[2](3480/5770): Loss: 59.1664 || Time: 0.3299 sec.\n",
      "===> Epoch[2](3500/5770): Loss: 207.5472 || Time: 0.3331 sec.\n",
      "===> Epoch[2](3520/5770): Loss: 289.8226 || Time: 0.3393 sec.\n",
      "===> Epoch[2](3540/5770): Loss: 87.4578 || Time: 0.3403 sec.\n",
      "===> Epoch[2](3560/5770): Loss: 143.1349 || Time: 0.3376 sec.\n",
      "===> Epoch[2](3580/5770): Loss: 231.9474 || Time: 0.3404 sec.\n",
      "===> Epoch[2](3600/5770): Loss: 168.7438 || Time: 0.3424 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 249.8330, Mean AP = 0.5752, Mean SSIM = 0.9521, Mean PSNR = 24.8090 || Time: 9.8783 sec.\n",
      "===> Epoch[2](3620/5770): Loss: 322.5424 || Time: 0.3284 sec.\n",
      "===> Epoch[2](3640/5770): Loss: 191.0338 || Time: 0.3410 sec.\n",
      "===> Epoch[2](3660/5770): Loss: 163.4012 || Time: 0.3316 sec.\n",
      "===> Epoch[2](3680/5770): Loss: 400.6508 || Time: 0.3324 sec.\n",
      "===> Epoch[2](3700/5770): Loss: 169.2110 || Time: 0.3415 sec.\n",
      "===> Epoch[2](3720/5770): Loss: 606.9556 || Time: 0.3465 sec.\n",
      "===> Epoch[2](3740/5770): Loss: 291.7895 || Time: 0.3285 sec.\n",
      "===> Epoch[2](3760/5770): Loss: 145.6891 || Time: 0.3369 sec.\n",
      "===> Epoch[2](3780/5770): Loss: 252.0567 || Time: 0.3291 sec.\n",
      "===> Epoch[2](3800/5770): Loss: 64.9527 || Time: 0.3388 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 244.1361, Mean AP = 0.5295, Mean SSIM = 0.9491, Mean PSNR = 24.7381 || Time: 9.8234 sec.\n",
      "===> Epoch[2](3820/5770): Loss: 110.8806 || Time: 0.3287 sec.\n",
      "===> Epoch[2](3840/5770): Loss: 159.8981 || Time: 0.3292 sec.\n",
      "===> Epoch[2](3860/5770): Loss: 138.6178 || Time: 0.3284 sec.\n",
      "===> Epoch[2](3880/5770): Loss: 175.2104 || Time: 0.3392 sec.\n",
      "===> Epoch[2](3900/5770): Loss: 255.1831 || Time: 0.3401 sec.\n",
      "===> Epoch[2](3920/5770): Loss: 175.8747 || Time: 0.3334 sec.\n",
      "===> Epoch[2](3940/5770): Loss: 72.7626 || Time: 0.3405 sec.\n",
      "===> Epoch[2](3960/5770): Loss: 322.9243 || Time: 0.3286 sec.\n",
      "===> Epoch[2](3980/5770): Loss: 375.4367 || Time: 0.3351 sec.\n",
      "===> Epoch[2](4000/5770): Loss: 291.7137 || Time: 0.3397 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 256.3409, Mean AP = 0.5746, Mean SSIM = 0.9520, Mean PSNR = 24.7010 || Time: 9.6852 sec.\n",
      "Saving state, iter: 4000\n",
      "===> Epoch[2](4020/5770): Loss: 84.2218 || Time: 0.3285 sec.\n",
      "===> Epoch[2](4040/5770): Loss: 339.5097 || Time: 0.3295 sec.\n",
      "===> Epoch[2](4060/5770): Loss: 147.0802 || Time: 0.3370 sec.\n",
      "===> Epoch[2](4080/5770): Loss: 253.4065 || Time: 0.3288 sec.\n",
      "===> Epoch[2](4100/5770): Loss: 89.4463 || Time: 0.3289 sec.\n",
      "===> Epoch[2](4120/5770): Loss: 258.5052 || Time: 0.3331 sec.\n",
      "===> Epoch[2](4140/5770): Loss: 135.1740 || Time: 0.3334 sec.\n",
      "===> Epoch[2](4160/5770): Loss: 127.9146 || Time: 0.3287 sec.\n",
      "===> Epoch[2](4180/5770): Loss: 235.1376 || Time: 0.3335 sec.\n",
      "===> Epoch[2](4200/5770): Loss: 285.4893 || Time: 0.3338 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 239.9459, Mean AP = 0.5842, Mean SSIM = 0.9522, Mean PSNR = 24.8622 || Time: 9.7492 sec.\n",
      "===> Epoch[2](4220/5770): Loss: 309.2871 || Time: 0.3298 sec.\n",
      "===> Epoch[2](4240/5770): Loss: 173.1672 || Time: 0.3276 sec.\n",
      "===> Epoch[2](4260/5770): Loss: 245.8351 || Time: 0.3291 sec.\n",
      "===> Epoch[2](4280/5770): Loss: 95.4161 || Time: 0.3328 sec.\n",
      "===> Epoch[2](4300/5770): Loss: 229.1210 || Time: 0.3336 sec.\n",
      "===> Epoch[2](4320/5770): Loss: 388.7770 || Time: 0.3310 sec.\n",
      "===> Epoch[2](4340/5770): Loss: 543.7175 || Time: 0.3311 sec.\n",
      "===> Epoch[2](4360/5770): Loss: 161.2214 || Time: 0.3469 sec.\n",
      "===> Epoch[2](4380/5770): Loss: 101.9612 || Time: 0.3283 sec.\n",
      "===> Epoch[2](4400/5770): Loss: 582.0853 || Time: 0.3523 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 253.7293, Mean AP = 0.5295, Mean SSIM = 0.9517, Mean PSNR = 24.8288 || Time: 9.5992 sec.\n",
      "===> Epoch[2](4420/5770): Loss: 73.6285 || Time: 0.3295 sec.\n",
      "===> Epoch[2](4440/5770): Loss: 123.1041 || Time: 0.3334 sec.\n",
      "===> Epoch[2](4460/5770): Loss: 98.4675 || Time: 0.3311 sec.\n",
      "===> Epoch[2](4480/5770): Loss: 284.0225 || Time: 0.3308 sec.\n",
      "===> Epoch[2](4500/5770): Loss: 251.4425 || Time: 0.3468 sec.\n",
      "===> Epoch[2](4520/5770): Loss: 300.5216 || Time: 0.3308 sec.\n",
      "===> Epoch[2](4540/5770): Loss: 588.8809 || Time: 0.3422 sec.\n",
      "===> Epoch[2](4560/5770): Loss: 287.6814 || Time: 0.3331 sec.\n",
      "===> Epoch[2](4580/5770): Loss: 264.0309 || Time: 0.3311 sec.\n",
      "===> Epoch[2](4600/5770): Loss: 325.5977 || Time: 0.3399 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 264.3195, Mean AP = 0.5711, Mean SSIM = 0.9518, Mean PSNR = 24.7754 || Time: 9.5786 sec.\n",
      "===> Epoch[2](4620/5770): Loss: 305.8795 || Time: 0.3290 sec.\n",
      "===> Epoch[2](4640/5770): Loss: 370.4400 || Time: 0.3287 sec.\n",
      "===> Epoch[2](4660/5770): Loss: 50.9332 || Time: 0.3282 sec.\n",
      "===> Epoch[2](4680/5770): Loss: 128.8833 || Time: 0.3311 sec.\n",
      "===> Epoch[2](4700/5770): Loss: 271.4720 || Time: 0.3384 sec.\n",
      "===> Epoch[2](4720/5770): Loss: 167.1124 || Time: 0.3427 sec.\n",
      "===> Epoch[2](4740/5770): Loss: 131.9294 || Time: 0.3392 sec.\n",
      "===> Epoch[2](4760/5770): Loss: 259.3962 || Time: 0.3336 sec.\n",
      "===> Epoch[2](4780/5770): Loss: 139.6684 || Time: 0.3332 sec.\n",
      "===> Epoch[2](4800/5770): Loss: 304.0780 || Time: 0.3412 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 246.5129, Mean AP = 0.5674, Mean SSIM = 0.8592, Mean PSNR = 22.7026 || Time: 9.6897 sec.\n",
      "===> Epoch[2](4820/5770): Loss: 120.8781 || Time: 0.3278 sec.\n",
      "===> Epoch[2](4840/5770): Loss: 345.6735 || Time: 0.3304 sec.\n",
      "===> Epoch[2](4860/5770): Loss: 380.7444 || Time: 0.3444 sec.\n",
      "===> Epoch[2](4880/5770): Loss: 458.9169 || Time: 0.3327 sec.\n",
      "===> Epoch[2](4900/5770): Loss: 529.7805 || Time: 0.3465 sec.\n",
      "===> Epoch[2](4920/5770): Loss: 209.3660 || Time: 0.3491 sec.\n",
      "===> Epoch[2](4940/5770): Loss: 463.0695 || Time: 0.3609 sec.\n",
      "===> Epoch[2](4960/5770): Loss: 252.6264 || Time: 0.3435 sec.\n",
      "===> Epoch[2](4980/5770): Loss: 264.6239 || Time: 0.3476 sec.\n",
      "===> Epoch[2](5000/5770): Loss: 161.3950 || Time: 0.3442 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 306.4703, Mean AP = 0.5811, Mean SSIM = 0.9504, Mean PSNR = 24.7011 || Time: 9.7579 sec.\n",
      "===> Epoch[2](5020/5770): Loss: 361.2282 || Time: 0.3560 sec.\n",
      "===> Epoch[2](5040/5770): Loss: 88.5236 || Time: 0.3288 sec.\n",
      "===> Epoch[2](5060/5770): Loss: 171.9198 || Time: 0.3350 sec.\n",
      "===> Epoch[2](5080/5770): Loss: 240.6663 || Time: 0.3313 sec.\n",
      "===> Epoch[2](5100/5770): Loss: 673.5310 || Time: 0.3349 sec.\n",
      "===> Epoch[2](5120/5770): Loss: 81.2566 || Time: 0.3320 sec.\n",
      "===> Epoch[2](5140/5770): Loss: 348.4905 || Time: 0.3348 sec.\n",
      "===> Epoch[2](5160/5770): Loss: 78.4296 || Time: 0.3319 sec.\n",
      "===> Epoch[2](5180/5770): Loss: 355.8478 || Time: 0.3349 sec.\n",
      "===> Epoch[2](5200/5770): Loss: 120.4413 || Time: 0.3329 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 263.1147, Mean AP = 0.5817, Mean SSIM = 0.9528, Mean PSNR = 24.5355 || Time: 9.7501 sec.\n",
      "===> Epoch[2](5220/5770): Loss: 114.1591 || Time: 0.3304 sec.\n",
      "===> Epoch[2](5240/5770): Loss: 225.0978 || Time: 0.3330 sec.\n",
      "===> Epoch[2](5260/5770): Loss: 265.3824 || Time: 0.3295 sec.\n",
      "===> Epoch[2](5280/5770): Loss: 257.1793 || Time: 0.3397 sec.\n",
      "===> Epoch[2](5300/5770): Loss: 157.6149 || Time: 0.3374 sec.\n",
      "===> Epoch[2](5320/5770): Loss: 334.0694 || Time: 0.3340 sec.\n",
      "===> Epoch[2](5340/5770): Loss: 164.0079 || Time: 0.3370 sec.\n",
      "===> Epoch[2](5360/5770): Loss: 54.4030 || Time: 0.3280 sec.\n",
      "===> Epoch[2](5380/5770): Loss: 192.8442 || Time: 0.3302 sec.\n",
      "===> Epoch[2](5400/5770): Loss: 127.1152 || Time: 0.3422 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 266.0328, Mean AP = 0.5958, Mean SSIM = 0.9528, Mean PSNR = 24.9272 || Time: 9.7576 sec.\n",
      "===> Epoch[2](5420/5770): Loss: 213.9551 || Time: 0.3283 sec.\n",
      "===> Epoch[2](5440/5770): Loss: 344.5200 || Time: 0.3299 sec.\n",
      "===> Epoch[2](5460/5770): Loss: 48.1759 || Time: 0.3395 sec.\n",
      "===> Epoch[2](5480/5770): Loss: 214.5989 || Time: 0.3387 sec.\n",
      "===> Epoch[2](5500/5770): Loss: 478.6024 || Time: 0.3314 sec.\n",
      "===> Epoch[2](5520/5770): Loss: 263.2093 || Time: 0.3310 sec.\n",
      "===> Epoch[2](5540/5770): Loss: 414.2425 || Time: 0.3528 sec.\n",
      "===> Epoch[2](5560/5770): Loss: 164.7162 || Time: 0.3426 sec.\n",
      "===> Epoch[2](5580/5770): Loss: 150.3217 || Time: 0.3399 sec.\n",
      "===> Epoch[2](5600/5770): Loss: 371.8318 || Time: 0.3703 sec.\n",
      "Evaluating detections\n",
      "Mean Loss = 243.1244, Mean AP = 0.5338, Mean SSIM = 0.9533, Mean PSNR = 24.7577 || Time: 9.9182 sec.\n",
      "===> Epoch 2 Complete: Avg. Loss: 135.0762 || Time: 2163.8245 sec.\n"
     ]
    }
   ],
   "source": [
    "train(SRDnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging code below, no need to run :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' YOU Donot need to run this ===> Loading some datasets')\n",
    "\n",
    "lr_path = os.path.join(opt.input_dir, opt.train_dataset)\n",
    "hr_path = os.path.join(opt.input_dir, opt.hr_dataset)\n",
    "\n",
    "fine_train_set = get_pair_set(lr_path, hr_path)\n",
    "train_data_loader = DataLoader(dataset=fine_train_set, num_workers=opt.threads, \\\n",
    "                               batch_size=opt.testBatchSize, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_test():\n",
    "    SDnet = DBPN2SSD('dbpn/models/DBPN_x4.pth', 'ssd/weights/ssd300_mAP_77.43_v2.pth', True)\n",
    "    net = SDnet\n",
    "    \n",
    "    if cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = True\n",
    "        net = net.cuda()\n",
    "\n",
    "    else:\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "\n",
    "    \n",
    "simple_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor ## UNCOMMENT THIS LINE IF YOU'RE ON A GPU!\n",
    "\n",
    "# Real samples were all associated with Ture labels - 1\n",
    "T_labels = torch.ones(logits_real.size()).type(dtype)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
